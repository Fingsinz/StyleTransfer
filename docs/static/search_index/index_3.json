{"/StyleTransfer/ref_and_notes/gan.html":{"title":"生成对抗网络","content":" title: 生成对抗网络 keywords: GAN desc: GAN文献及笔记 date: 2025 02 01 id: ref_GAN [Generative Adversarial Networks](https://arxiv.org/abs/1406.2661) *Goodfellow I , Pouget Abadie J , Mirza M ,et al.Generative Adversarial Nets[J].MIT Press, 2014.DOI:10.3156/JSOFT.29.5_177_2.* > We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to ½ everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples. **摘要**：论文提出一个通过对抗过程估计生成模型的新框架。在对抗过程中，同时训练两个模型：一个捕获数据分布的生成器 G，和一个估计样本来自训练数据还是生成器 G 的判别器 D。生成器 G 的训练过程是最大化判别器 D 犯错的概率。这个框架相当于一个极大极小二人博弈游戏。在任意的 G 和 D 函数空间中，存在唯一解，使得生成器 G 能复刻训练集的数据分布，同时判别器 D 对于生成器 G 生成的任意样本作出的判断都是真假参半（真假概率各半）。如果生成器 G 和判别器 D 都定义为多层感知器，那么整个系统可以使用误差反向传播进行训练。在模型的训练过程以及样本的生成中，不需要使用马尔科夫链或者展开的近似推理网络。通过对生成的样本进行定性和定量评估，实验证明了该框架的潜力。 ## GAN 模型 GAN包含两个模型： 1. **生成器（Generator, G）**：将随机噪声映射到数据空间，目标是生成与真实数据分布 $p_{\\text{data}}$ 一致的样本。 2. **判别器（Discriminator, D）**：区分输入样本来自真实数据还是生成器，输出为样本真实性的概率。 两者通过**极小极大博弈**进行训练： 为了学习生成器在数据 $x$ 上的分布 $p_g$，定义输入噪声变量 $p_z(z)$ 的先验，然后将数据空间的映射表示为 $G(z; \\theta_g)$，其中 $G$ 是由具有参数 $\\theta_g$ 的多层感知器表示的可微函数。 定义第二个多层感知器 $D(x; \\theta_d)$，其输出一个标量。$D(x)$ 表示 $x$ 来自真实数据而不是 $p_g$ 的概率。 **训练判别器 D，最大化正确分类训练样本和生成器 G 生成样本的概率；同时训练生成器 G，最小化 $\\log(1−D(G(z)))$，即让生成样本 $G(z)$ 被判别器误判为真实样本（$D(G(z))→1$）**。 综上所述，GAN 的训练过程可表示为： $$ \\min_G \\max_D V(D, G) \\mathbb{E}_{x \\sim p_{\\text{data}}(x)} [\\log D(x)] + \\mathbb{E}_{z \\sim p_z(z)} [\\log(1 D(G(z)))]\\tag{1} $$ 当生成器 G 分布 $p_g p_{data}$，判别器 D 的最优解为 $D^*(x) \\frac{1}{2}$ 时，目标函数达到最小值 $\\log({\\frac{1}{2}}) + \\log(1 \\frac{1}{2}) \\log{4}$。 ## 网络理论 ### 算法步骤 *小批量随机梯度下降，$k$ 为超参数。* ``` for i 1, iterations do for k steps do m 个噪声样本的小批量样本 {z(1),., z(m)}，来自噪声先验 pg(z)。 m 个真实样本的小批量样本 {x(1),., x(m)}，来自真实数据集。 通过公式 2 提升判别器随机梯度来更新判别器。 end for m 个噪声样本的小批量样本 {z(1),., z(m)}，来自噪声先验 pg(z)。 通过公式 3 降低生成器随机梯度来更新生成器。 end for ``` $$ \\nabla_{\\theta_d} \\frac{1}{m} \\sum_{i 1}^m \\left[\\log D(x^{(i)}) + \\log(1 D(G(z^{(i)}))) \\right] \\tag{2} $$ $$ \\nabla_{\\theta_g} \\frac{1}{m} \\sum_{i 1}^m \\log\\left(1 D(G(z^{(i)}))\\right) \\tag{3} $$ 训练过程的巧思： 1. **在 $k$ 步优化判别器 D 和 $1$ 步优化生成器 G 之间交替进行**：在 one step 的内部循环中优化判别器 D 在计算上是不可行的，并且容易在有限的数据集上导致过拟合。 2. **最大化 $\\log D(G(z))$ 代替最小化 $\\log(1−D(G(z)))$ 训练生成器 G**：在生成器 G 效果很差时，判别器 D可以以高置信度拒绝样本，这种情况下，$\\log(1−D(G(z)))$ 不起作用。 原文中提供下图： ![](../static/images/GAN/fig1.png) *注：黑色散点线为真实数据的分布；绿色实线为生成器 $G$ 生成数据的分布；蓝色虚线为判别器 $D$ 的分布，区分黑色散点与绿色实线。最下面的直线为均匀采样 $z$ 的域；其上面的直线是 $x$ 域的一部分。向上的箭头表示 $x G(z)$ 的映射关系。* 图 (a)：对抗接近收敛，$p_g$ 接近 $p_{data}$，判别器部分分类正确（能否分辨出真实数据和生成数据）。 图 (b)：在算法的内部循环中，判别器 D 向着分类数据训练，收敛在 $D^*(x) \\frac {p_{data}(x)}{p_{data}(x) + p_g(x)}$。 图 (c)：更新生成器 $G$ 后，判别器 $D$ 的梯度引导 $G(z)$ 偏向更有可能被归类为真实数据的区域。 图 (d)：经过若干步训练后，如果 $G$ 和 $D$ 有足够的容量，它们会收敛到 $p_g p_{data}$，此时 $D$ 无法区分出真实数据和生成数据，即 $D(x) \\frac {1}{2}$。 ### 解释全局最优解 $p_g p_{data}$ **命题 1.** 对于固定的生成器 $G$，最优判别器 $D$ 为： $$ D^*_G(x) \\frac {p_{data}(x)}{p_{data}(x) + p_g(x)} $$ **证明：** 给定任何生成器 $G$ 的判别器 $D$ 的训练标准是最大化 $V(G, D)$。 $$ V(G,D) \\int_x p_{data}(x) \\log(D(x))dx + \\int_z p_z(z) \\log(1 D(g(z)))dz\\tag{4} $$ 通过变量替换 $G(z) x \\sim p_g(x)$，式(4)改写为： $$ V(G,D) \\int_x \\left[p_{data}(x) \\log(D(x)) + p_g(x) \\log(1 D(x))\\right] dx $$ > *生成器 $G$ 将噪声输入 $z \\sim p_z(z)$ 映射为样本 $x G(z)$，隐式定义了生成样本的分布 $p_g(x)$。当 $z$ 服从噪声先验 $p_z(z)$ 分布时，$x G(z)$ 的分布即为 $p_g(x)$；若 $z \\sim p_z(z)$，则 $x G(z)\\sim p_g(x)$。* > *对于变量替换定理，对于任意函数 $h(x)$，若 $x$ 是随机变量 $z$ 的映射 $x G(z)$，则关于 $z$ 的期望可以转换为关于 $x$ 的期望：$\\mathbb{E}_{z \\sim p_z(z)}[h(G(z))] \\mathbb{E}_{x \\sim p_g(x)}[h(x)]$。* 对于每个样本 $x$，求 $D(x)$ 使得 $V(D,G)$ 最大化。这是一个单变量优化问题，最优解为： $$ D^*_G(x) \\frac {p_{data}(x)}{p_{data}(x) + p_{g}(x)} $$ 将最优判别器代入到目标函数有： $$ \\begin{aligned} C(G) & \\max_D V(G,D)\\\\ & \\mathbb{E}_{x \\sim p_{\\text{data}}} \\left[\\log D^*_G(x) \\right] + \\mathbb{E}_{z \\sim p_z} \\left[\\log(1 D^*_G(G(z))) \\right] \\\\ & \\mathbb{E}_{x \\sim p_{\\text{data}}} \\left[\\log D^*_G(x) \\right] + \\mathbb{E}_{x \\sim p_g} \\left[\\log(1 D^*_G(x)) \\right]\\\\ & \\mathbb{E}_{x \\sim p_{\\text{data}}} \\left[\\log \\frac {p_{data}(x)}{p_{data}(x) + p_{g}(x)} \\right] + \\mathbb{E}_{x \\sim p_g} \\left[\\log \\frac {p_{g}(x)}{p_{data}(x) + p_{g}(x)} \\right] \\end{aligned}\\tag{5} $$ **定理 1.** 当且仅当 $p_g p_{data}$ 时，$C(G)$ 达到的全局最小值 $ \\log 4$。 **证明：** 对于 $p_g p_{data}$，有 $D^*_G(x) \\frac{1}{2}$。因此： $$ C(G) \\mathbb{E}_{x\\sim p_{data}} \\frac {p_{data}(x)}{p_{data}(x) + p_{g}(x)} + \\mathbb{E}_{x\\sim p_{g}} \\frac {p_{g}(x)}{p_{data}(x) + p_{g}(x)} \\log \\frac {1}{2} + \\log \\frac {1}{2} \\log 4 $$ GAN 的优化目标是最小化生成模型分布 $p_g$ 和真实数据分布 $p_{data}$ 之间的差异，将目标函数中的对数概率表达为 KL 散度的形式。引入变形以关联 KL 散度： $$ \\begin{aligned} \\log \\frac {p_{data}(x)}{p_{data}(x) + p_{g}(x)} \\log \\frac {p_{data}(x)}{\\frac {p_{data}(x)+p_g(x)}{2}} \\log 2 \\\\ \\log \\frac {p_{g}(x)}{p_{data}(x) + p_{g}(x)} \\log \\frac {p_{g}(x)}{\\frac {p_{data}(x)+p_g(x)}{2}} \\log 2 \\end{aligned} $$ 所以， $$ \\begin{aligned} C(G) & \\log 4 + \\mathbb{E}_{x\\sim p_{data}} \\left[\\log \\frac {p_{data}(x)}{\\frac {p_{data}(x)+p_g(x)}{2}} \\right] + \\mathbb{E}_{x\\sim p_{g}} \\left[\\log \\frac {p_{g}(x)}{\\frac {p_{data}(x)+p_g(x)}{2}} \\right] \\\\ & \\log 4 + \\text{KL}\\left(p_{data}\\frac{p_{data}+p_g}{2}\\right) + \\text{KL}\\left(p_g\\frac{p_{data}+p_g}{2}\\right) \\\\ & \\log 4 + 2 \\cdot \\text{JSD}(p_{data} p_g) \\end{aligned} $$ >其中，KL 散度是衡量两个分布差异的常见方法，定义为：$\\text{KL}(pq) \\mathbb{E}_{x\\sim p} \\log \\frac {p(x)}{q(x)}$。Jensen Shannon 散度（JSD）是 KL 散度的一个对称版本，是衡量两个分布差异的对称性指标，定义为：$\\text{JSD}(pq) \\frac {1}{2} \\text{KL}(p \\frac {p + q}{2}) + \\frac {1}{2} \\text{KL}(q \\frac {p + q}{2})$。 由于 JSD 非负，当且仅当 $p q$ 时为零，因此： $$ C(G) \\geq \\log 4, 且等号成立当且仅当 p_g p_{data} $$ 证毕。 ### 解释算法收敛性 **命题 2.** 如果生成器 $G$ 和判别器 $D$ 都有足够的容量，并且算法的每一步都允许判别器在给定 $G$ 的情况下达到最优，并更新 $p_g$ 以改进标准 $\\mathbb{E}_{x\\sim p_{data}}[\\log D^*_G(x)] + \\mathbb{E}_{x\\sim p_{g}}[\\log (1 D^*_G(x))]$，则 $p_g$ 收敛到 $p_{data}$。 **证明：** 考虑 $V(G, D) U(p_g, D)$ 作为 $p_g$ 的函数。$U(p_g, D)$ 是凸函数，且全局最优解唯一。通过梯度下降更新 $p_g$，其参数更新方向始终朝向 JSD 减小的方向，从而保证收敛。 ## 代码实验 实验代码如下，详细代码位于[Github](https://github.com/Fingsinz/StyleTransfer/blob/main/src/01.ref_and_note/01.GAN.py)： <details> <summary>GAN MNIST 实验代码</summary> ```python ''' Created on 2025.02.01 @Author: Fingsinz (fingsinz@foxmail.com) @Reference: 1. https://arxiv.org/abs/1406.2661 ''' import time import os import torch import numpy as np import torch.nn as nn import torch.optim as optim from torch.utils.data import DataLoader from torchvision import datasets, transforms import matplotlib.pyplot as plt # 配置参数 class Config(): data_folder: str './data' # 数据集路径, 此处用 MNIST 做测试 batch_size: int 128 # batch 大小 epochs: int 10 # 训练轮数 lr: float 0.0002 # 学习率 betas: tuple (0.5, 0.999) # Adam 的超参数 k_steps: int 5 # k 值 latent_dim: int 100 # 隐变量维度 device: str 'cuda' if torch.cuda.is_available() else 'cpu' # 生成器 class Generator(nn.Module): def __init__(self, latent_dim): super().__init__() self.model nn.Sequential( nn.Linear(latent_dim, 256), nn.LeakyReLU(0.2), nn.Linear(256, 512), nn.LeakyReLU(0.2), nn.Linear(512, 1024), nn.LeakyReLU(0.2), nn.Linear(1024, 28 * 28), nn.Tanh() ) def forward(self, x): return self.model(x).view( 1, 1, 28, 28) # 判别器 class Discriminator(nn.Module): def __init__(self): super().__init__() self.model nn.Sequential( nn.Flatten(), nn.Linear(28 * 28, 1024), nn.LeakyReLU(0.2, inplace True), nn.Linear(1024, 512), nn.LeakyReLU(0.2, inplace True), nn.Linear(512, 256), nn.LeakyReLU(0.2, inplace True), nn.Linear(256, 1), nn.Sigmoid() ) def forward(self, x): return self.model(x) # GAN 模型 class GAN(): def __init__(self, config): self.config config self.generator Generator(config.latent_dim).to(config.device) self.discriminator Discriminator().to(config.device) self.criterion nn.BCELoss() self.g_optimizer optim.Adam(self.generator.parameters(), lr config.lr, betas config.betas) self.d_optimizer optim.Adam(self.discriminator.parameters(), lr config.lr, betas config.betas) self.real_label 1 self.fake_label 0 def get_data(self): transform transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,)) ]) train_dataset datasets.MNIST(root self.config.data_folder, train True, download True, transform transform) train_loader DataLoader(train_dataset, batch_size self.config.batch_size, shuffle True) return train_loader def train(self): train_loader self.get_data() epochs self.config.epochs g_loss 0 d_real_loss 0 d_fake_loss 0 for epoch in range(epochs): for i, (images, _) in enumerate(train_loader): batch_size images.size(0) images images.to(self.config.device) # 判别器训练 if (i + 1) % self.config.k_steps ! 0: self.d_optimizer.zero_grad() # 训练真实数据 labels torch.full((batch_size,), self.real_label, device self.config.device).float() output self.discriminator(images) loss_real self.criterion(output.view( 1), labels) loss_real.backward() # 训练假数据 z torch.randn(batch_size, self.config.latent_dim, device self.config.device) fake_images self.generator(z) labels.fill_(self.fake_label).float() output self.discriminator(fake_images.detach()) loss_fake self.criterion(output.view( 1), labels) loss_fake.backward() self.d_optimizer.step() d_real_loss loss_real.item() d_fake_loss loss_fake.item() # 判别器训练 # 生成器训练 else: self.g_optimizer.zero_grad() labels.fill_(self.real_label).float() output self.discriminator(fake_images) loss_g self.criterion(output.view( 1), labels) loss_g.backward() self.g_optimizer.step() g_loss loss_g.item() # 生成器训练 if i % 100 0: print(f\"[{time.strftime('%Y %m %d %H:%M:%S', time.localtime())}] \" + f\"Epoch [{epoch}/{epochs}], Step [{i}/{len(train_loader)}], \" f\"D Loss: {d_real_loss:.4f} + {d_fake_loss:.4f}, G Loss: {g_loss:.4f}\") self.save_generated_images(epoch + 1) def save_generated_images(self, epoch): \"\"\" 保存训练效果图片 参数: epoch (int): 当前轮数 \"\"\" z torch.randn(64, self.config.latent_dim, device self.config.device) fake_images self.generator(z) fake_images fake_images.cpu().detach().numpy() fake_images np.transpose(fake_images, (0, 2, 3, 1)) fig, axes plt.subplots(8, 8, figsize (8, 8)) for i in range(8): for j in range(8): axes[i, j].imshow(fake_images[i * 8 + j, :, :, 0], cmap 'gray') axes[i, j].axis('off') if not os.path.exists('gan_generated_images'): os.makedirs('gan_generated_images') plt.savefig(f'./gan_generated_images/epoch_{epoch}.png') plt.close() if __name__ '__main__': config Config() gan GAN(config) gan.train() ``` </details> GAN 对于 MNIST 数据集效果可如下所示： <table> <th>第一轮生成的图片</th> <th>第十轮生成的图片</th> <tr> <td><img src \"../static/images/GAN/epoch_1.png\"></td> <td><img src \"../static/images/GAN/epoch_10.png\"></td> </tr> </table> ## 论文优缺点及未来工作 优点（DeepSeek总结）： 生成样本质量高：GAN生成的图像、音频等数据具有极高的逼真度，尤其在图像生成任务中表现出色（如人脸、艺术作品生成）。生成器通过对抗训练不断优化，以欺骗判别器，最终生成的样本细节丰富、接近真实数据分布。 无需显式建模数据分布：GAN通过对抗过程直接学习数据分布，无需预先定义概率密度函数（如VAE需要假设潜在变量的分布），适用于复杂高维数据（如自然图像）。 生成多样性：在理想情况下，GAN能够覆盖真实数据的所有模式，生成多样化样本。相比之下，某些模型（如朴素自回归模型）可能因逐像素生成导致模式单一化。 无监督学习能力：GAN仅需未标注数据即可训练，适合缺乏标签的场景（如艺术创作、数据增强）。 灵活的应用扩展：GAN框架可轻松扩展为条件生成（cGAN）、图像翻译（CycleGAN）、超分辨率（SRGAN）等任务，适应多种生成需求。 缺点（DeepSeek总结）： 训练不稳定 模式坍缩（Mode Collapse）：生成器可能仅生成少数几种样本，忽略数据多样性。 梯度问题：若判别器过强，生成器梯度消失；若生成器过强，判别器无法提供有效反馈。 评估困难 缺乏显式似然函数，难以直接计算生成样本的概率。 常用指标（如Inception Score、FID）依赖预训练模型，可能无法全面反映生成质量。 超参数敏感：学习率、网络结构、正则化方法等对训练结果影响显著，需反复调参。 理论分析复杂 收敛性难以保证，实际训练可能陷入局部最优。 均衡状态（纳什均衡）在有限模型容量下难以达到。 生成不可控性 生成过程缺乏显式约束，可能产生不合理样本（如人脸扭曲）。 对离散数据（如文本）生成效果较差，因梯度无法通过离散变量传递。 计算资源消耗大：训练高质量GAN需要大量数据和计算资源（如GPU），耗时较长。 未来工作： 更好地理解这种框架，例如在高维空间中的表现； 探索其他算法和数据结构，例如使用卷积神经网络作为掩码器； 探索其他训练方法，例如使用梯度反向传递训练模型； 探索其他损失函数，例如使用KL损失函数； 探索其他训练方法，例如使用GAN训练模型。"},"/StyleTransfer/ref_and_notes/pytorch_basic_workflow.html":{"title":"PyTorch 基本工作流","content":"Reference:[PyTorchWorkflowFundamentals](https://www.learnpytorch.io/01_pytorch_workflow/)*该页面由JupyterNotebook生成，原文件于[Github](https://github.com/Fingsinz/StyleTransfer/tree/main/src/02.pytorch_learning/pytorch_basic_workflow.ipynb)*#先导入包importtorchfromtorchimportnnimportmatplotlib.pyplotasplttorch.__version__##准备数据集数据可以是很多东西，如一个表格、任何类型的图像、视频、歌曲或播客等音频文件，蛋白质结构，文本等等。机器学习是一个由两部分组成：1.把你的数据转换成数字表示。2.选择或构建一个模型来尽可能地学习数据的表征。获得数据之后，需要将数据划分为训练集、验证集和测试集。类型目的占比使用情况: :: :: :: :训练集模型从这些数据里面学习（比如学习的课程材料）\\~60\\~80%必须有验证集模型会根据这些数据进行调整（比如期末考试前的练习）\\~10\\~20%不必有测试集模型根据这些数据进行评估，以测试它学到了什么（比如期末考试）\\~10\\~20%必须有#创建一个y weight*x+bias的数据集weight 0.7bias 0.3X torch.arange(0,1,0.02).unsqueeze(dim 1)y weight*X+bias#划分训练集和测试集train_split int(0.8*len(X))X_train,y_train X[:train_split],y[:train_split]X_test,y_test X[train_split:],y[train_split:]defplot_predictions(train_data X_train,train_labels y_train,test_data X_test,test_labels y_test,predictions None):plt.figure(figsize (5,3))plt.scatter(train_data,train_labels,c \"b\",s 4,label \"Trainingdata\")plt.scatter(test_data,test_labels,c \"g\",s 4,label \"Testingdata\")ifpredictionsisnotNone:plt.scatter(test_data,predictions,c \"r\",s 4,label \"Prediction\")plt.legend(prop {\"size\":8})plot_predictions()##构建模型###PyTorch模型构建要点PyTorch有四个基本模块，可以用它来创建神经网络： [torch.nn](https://pytorch.org/docs/stable/nn.html)； [torch.optim](https://pytorch.org/docs/stable/optim.html)； [torch.utils.data.Dataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset)； [torch.utils.data.DataLoader](https://pytorch.org/docs/stable/data.html)；模块作用: :: :`torch.nn`包含计算图的所有构建块`torch.nn.Parameter`存储可用于`nn.Module`的张量。如果`requires_grad True`则自动计算梯度（用于通过梯度下降更新模型参数），这通常被称为“autograd”`torch.nn.Module`所有神经网络模块的基类，神经网络的所有构建块都是子类。在PyTorch中构建一个神经网络，模型应该继承`nn.Module`，需要实现`forward()`方法`torch.optim`包含各种优化算法（这些算法告诉存储在`nn.Parameter`中的模型参数。如何最好地改变，以改善梯度下降，从而减少损失)`defforward()`所有的`nn.Module`子类都需要一个`forward()`方法，定义传递给特定`nn.Module`的数据进行的计算（例如线性回归公式）简而言之： `nn.Module`包括大的构建块，如神经网络中的层； `nn.Parameter`包括小的参数，比如权重和偏置，众多参数构成`nn.Module`； `forward()`定义了在`nn.Module`中对输入的计算； `torch.optim`包含如何改进`nn.Parameter`中的参数的算法，以更好地表征数据一个简单的神经网络例子：classLinearRegressionModel(nn.Module):def__init__(self):super().__init__()self.weights nn.Parameter(torch.randn(1,dtype torch.float),requires_grad True)self.bias nn.Parameter(torch.randn(1,dtype torch.float),requires_grad True)defforward(self,x:torch.Tensor) >torch.Tensor:returnself.weights*x+self.bias###检视模型中的内容使用`model.parameters()`检查参数：torch.manual_seed(42)model_0 LinearRegressionModel()list(model_0.parameters())使用`model.state_dict()`获得模型状态（包含什么）：model_0.state_dict()###使用`torch.inference_mode()`进行预测`torch.inference_mode()`关闭了一些东西，比如梯度跟踪（训练所必需的，但不是推理所必需的），所以`forward`传递更快。withtorch.inference_mode():y_preds model_0(X_test)plot_predictions(predictions y_preds)由图可知模型预测距离真实值仍有一段距离，所以需要训练模型以达到更好的效果。##训练模型###建立损失函数和优化器为了让模型自己更新参数，需要添加损失函数和优化器。功能作用PyTorch的形式常用值: :: :: :: :损失函数测量模型的预测（`y_preds`）与真值标签（`y_test`）相比的错误程度。越低越好`torch.nn`中有很多内置的损失函数回归问题的平均绝对误差（MAE，`torch.nn.L1Loss()`）；二元分类问题的二元交叉熵（`torch.nn.BCELoss()`）优化器告诉模型如何更新其内部参数以最大程度地降低损失`torch.optim`中的各种优化函数实现随机梯度下降（`torch.optim.SGD()`）；Adam优化器（`torch.optim.Adam()`）为模型添加损失函数和优化器：###训练循环训练过程有以下步骤：序号步骤做法代码: :: :: :: :1前向传播模型将所有训练数据遍历一次，执行其`forward()`函数计算`model(x_train)`2计算损失将模型的输出（预测）与真实数据进行评估，计算损失值`loss loss_fn(y_pred,y_train)`3梯度归零优化器的梯度被设置为零（默认情况下它们是累积的），因此它们可以为特定的训练步骤重新计算`optimizer.zero_grad()`4反向传播损失计算每个要更新的模型参数的损失梯度（每个参数`requires_grad True`）`loss.backward()`5更新参数使用`requires_grad True`更新损耗梯度的参数`optimizer.step()`###测试循环测试过程有以下步骤：序号步骤做法代码: :: :: :: :1前向传播模型将所有训练数据遍历一次，执行其`forward()`函数计算`model(x_train)`2计算损失将模型的输出（预测）与真实数据进行评估，计算损失值`loss loss_fn(y_pred,y_train)`3计算评估指标（可选）计算其他评估指标，例如测试集上的准确性自定义函数###训练并测试代码torch.manual_seed(42)device \"cuda\"iftorch.cuda.is_available()else\"cpu\"X_train X_train.to(device)y_train y_train.to(device)X_test X_test.to(device)y_test y_test.to(device)model_0 model_0.to(device)epochs 200train_loss_values []test_loss_values []epoch_cnt []loss_fn nn.L1Loss()#损失函数optimizer torch.optim.SGD(params model_0.parameters(),lr 0.01)#优化器forepochinrange(epochs):model_0.train()#设置为训练模式#1.前向传播y_pred model_0(X_train)#2.计算损失loss loss_fn(y_pred,y_train)#3.梯度归零、反向传播、更新参数optimizer.zero_grad()loss.backward()optimizer.step()model_0.eval()#设置为评估模式withtorch.inference_mode():test_pred model_0(X_test)test_loss loss_fn(test_pred,y_test.type(torch.float))ifepoch%20 0:epoch_cnt.append(epoch)train_loss_values.append(loss.cpu().detach().numpy())test_loss_values.append(test_loss.cpu().detach().numpy())print(f\"{epoch}/{epochs}MAE训练损失:{loss}MAE测试损失:{test_loss}\")0/200 MAE 训练损失: 0.31288135051727295 MAE 测试损失: 0.48106518387794495 20/200 MAE 训练损失: 0.08908725529909134 MAE 测试损失: 0.21729658544063568 40/200 MAE 训练损失: 0.04543796926736832 MAE 测试损失: 0.11360953003168106 60/200 MAE 训练损失: 0.03818932920694351 MAE 测试损失: 0.08886633068323135 80/200 MAE 训练损失: 0.03132382780313492 MAE 测试损失: 0.07232122868299484 100/200 MAE 训练损失: 0.024458957836031914 MAE 测试损失: 0.05646304413676262 120/200 MAE 训练损失: 0.01758546754717827 MAE 测试损失: 0.04060482606291771 140/200 MAE 训练损失: 0.010716589167714119 MAE 测试损失: 0.024059748277068138 160/200 MAE 训练损失: 0.003851776709780097 MAE 测试损失: 0.008201557211577892 180/200 MAE 训练损失: 0.008932482451200485 MAE 测试损失: 0.005023092031478882损失随着时间的推移而下降，绘图：plt.figure(figsize (5,3))plt.plot(epoch_cnt,train_loss_values,label \"TrainLoss\")plt.plot(epoch_cnt,test_loss_values,label \"TestLoss\")plt.title(\"LossCurves\")plt.ylabel(\"Loss\")plt.xlabel(\"Epochs\")plt.legend()输出一下训练得到的`weight`和`bias`：print(model_0.state_dict())print(f\"{weight},{bias}\")OrderedDict([('weights', tensor([0.6990], device 'cuda:0')), ('bias', tensor([0.3093], device 'cuda:0'))]) 0.7, 0.3由此可知训练得到的参数与实际的参数已经相差很小了。##使用训练后的PyTorch模型进行推理在使用PyTorch模型进行预测（也称为执行推理）时，需要记住三件事：1.将模型设置为评估模式（`model.eval()`）。2.使用推理模式上下文管理器（使用`torch.inference_mode()`）进行预测。3.所有的预测都应该在同一设备上进行（仅在GPU上的数据和模型或仅在CPU上的数据和模型）。前两项确保关闭PyTorch在训练期间在幕后使用的所有有用的计算和设置，但这些计算和设置对于推理是不必要的（这导致更快的计算）。第三个确保你不会遇到跨设备错误。最后查看整体的分布：model_0.eval()withtorch.inference_mode():y_preds model_0(X_test)plot_predictions(predictions y_preds.cpu())##保存和加载模型比如在服务器上训练模型后，需要转移到本地或其他地方进行使用。方法作用: :: :`torch.save`使用Python的`pickle`实用程序将序列化的对象保存到磁盘。模型、张量和其他各种Python对象（如字典）都可以使用`torch.save`保存`torch.load`使用`pickle`的unpickling特性来反序列化并将文件（如模型，张量或字典）加载到内存中。也可以设置加载对象到哪个设备（CPU，GPU等）`torch.nn.Module.load_state_dict`使用已保存的`state_dict()`对象加载模型的参数字典（`model.state_dict()`）###保存模型的参数字典torch.save(obj model_0.state_dict(),f \"model_0.pth\")###加载参数字典到模型中loaded_model_0 LinearRegressionModel()loaded_model_0.load_state_dict(torch.load(f \"model_0.pth\",weights_only True))#测试看看预测结果是否相等loaded_model_0.to(device)loaded_model_0.eval()withtorch.inference_mode():loaded_model_preds loaded_model_0(X_test)loaded_model_preds y_preds"},"/StyleTransfer/ref_and_notes/pytorch_classification.html":{"title":"PyTorch 神经网络分类","content":"Reference:[PyTorchNeuralNetworkClassification](https://www.learnpytorch.io/02_pytorch_classification/)*该页面由JupyterNotebook生成，原文件于[Github](https://github.com/Fingsinz/StyleTransfer/tree/main/src/02.pytorch_learning/pytorch_classification.ipynb)*#先导入包importtorchfromtorchimportnnimportmatplotlib.pyplotasplttorch.__version__分类问题有二分类、多分类、多标签等情况。二分类问题则是或不是；多分类问题具有多个类别区分；多标签问题则一个目标可以被分配多个选项。##分类神经网络的结构分类神经网络的一般架构：项目二分类多分类: :: :: :输入层Shape（`in_features`）与特征数相同与特征数相同隐藏层特定问题特定分析特定问题特定分析每个隐藏层的神经元数量特定问题特定分析，一般从10到512特定问题特定分析，一般从10到512输出层Shape（`out_features`）1（一个类别）每个类1个输出隐藏层激活函数通常是ReLU通常是ReLU输出层激活函数Sigmoid（`torch.sigmoid`）Softmax（`torch.softmax`）损失函数二元交叉熵（`torch.nn.BCELoss`）交叉熵（`torch.nn.CrossEntropyLoss`）优化器SGD，AdamSGD，Adam##准备二分类数据集###输入和输出形状使用Scikit Learn中的`make_circles()`方法生成两个带有不同颜色圆点的圆。*需要安装Scikit Learn：`pipinstallscikit learn`*fromsklearn.datasetsimportmake_circlesn_samples 1000X,y make_circles(n_samples,noise 0.03,random_state 42)plt.scatter(x X[:,0],y X[:,1],c y,cmap plt.cm.RdYlBu)看看输入Shape和输出Shape，然后弄清楚输入层Shape（特征数）和输出层Shape。X.shape,y.shape#输入Shape和输出ShapeX[0].shape,y[0].shape#输入层Shape和输出层Shape这说明X的一个样本有两个特征（向量），而对应的y只有一个特征（标量）。 有两个输入对应一个输出。###划分数据集具体来说：1.将数据转换为张量。2.将数据分成训练集和测试集。X torch.from_numpy(X).type(torch.float)y torch.from_numpy(y).type(torch.float)X.dtype,y.dtype使用Scikit Learn中的函数`train_test_split()`。`test_size 0.2`（80%训练，20%测试），因为分割是随机发生的，所以使用`random_state 42`，使得随机可复现。fromsklearn.model_selectionimporttrain_test_splitX_train,X_test,y_train,y_test train_test_split(X,y,test_size 0.2,random_state 42)len(X_train),len(y_train),len(X_test),len(y_test)##构建分类模型构建模型的步骤：1.设置与设备相关的代码。2.通过继承`nn.module`来构造一个模型。3.定义损失函数和优化器。4.创建一个训练循环。###设置设备#1.设置设备device \"cuda\"iftorch.cuda.is_available()else\"cpu\"device###构建模型对象模型类的操作：1.继承`nn.Module`。2.在构造函数中创建2层`nn.Linear`线性层，能够处理X和y的形状。3.定义一个`forward()`方法，该方法包含模型的前向传递计算。4.实例化模型类并将其发送到目标设备。classCircleModelV0(nn.Module):def__init__(self):super().__init__()self.layer_1 nn.Linear(in_features 2,out_features 5)self.layer_2 nn.Linear(in_features 5,out_features 1)defforward(self,x):returnself.layer_2(self.layer_1)model_0 CircleModelV0().to(device)model_0由上面代码可知该模型类的结构为：`2(输入层) >5(隐藏层) >1(输出层)`也可以使用`nn.Sequential`执行与上面相同的操作。`nn.Sequential`按层出现的顺序对输入数据执行前向传递计算。model_0 nn.Sequential(nn.Linear(in_features 2,out_features 5),nn.Linear(in_features 5,out_features 1)).to(device)model_0自定义模型类可以自定义更多细节，而`nn.Sequential()`则更方便。###定义损失函数和优化器常见损失函数：损失函数适用类型代码: :: :: :交叉熵损失函数多分类`torch.nn.CrossEntropyLoss`平均绝对误差MAE，L1Loss回归问题`torch.nn.L1Loss`均方误差MSE，L2Loss回归问题`torch.nn.MSELoss`常见优化器：优化器适用类型代码: :: :: :随机梯度下降（SGD）分类问题、回归问题等`torch.optim.SGD()`Adam分类问题、回归问题等`torch.optim.Adam()`此处讨论二分类问题，使用一个二元交叉熵损失函数。>注意：损失函数是衡量模型预测错误程度的函数，损失越高，模型越差。>>此外，PyTorch文档经常将损失函数称为“损失准则（losscriterion）”或“准则（criterion）”，这些都是描述同一事物的不同方式。二元交叉熵函数有`torch.nn.BCELoss()`和`torch.nn.BCEWithLogitsLoss()`。 `torch.nn.BCELoss()`：创建一个损失函数，用于测量目标（标签）和输入（特征）之间的二进制交叉熵。 `torch.nn.BCEWithLogitsLoss()`：它内置了一个sigmoid层，其他这与上面的相同。`torch.nn.BCEWithLogitsLoss()`的文档指出，它比在`nn.Sigmoid`层之后使用`torch.nn.BCELoss()`在数值上更稳定。对于优化器，将使用`torch.optim.SGD()`以0.1的学习率优化模型参数。loss_fn nn.BCEWithLogitsLoss()optimizer torch.optim.SGD(params model_0.parameters(),lr 0.1)评估指标可用于提供关于模型运行情况的另一个视角。如果一个损失函数衡量模型的错误程度，那么也有评估指标衡量他的正确程度。defaccuracy_fn(y_true,y_pred):correct torch.eq(y_true,y_pred).sum().item()acc (correct/len(y_pred))*100returnacc##训练分类模型###将原始输出变成标签线性层的公式为：$$y x\\cdot\\text{Weights}^T+bias$$模型的原始输出通常被称为logits。使用激活函数将logits转换成与真值标签相比较的数字。###构建训练和测试循环torch.manual_seed(42)epochs 100X_train,y_train X_train.to(device),y_train.to(device)X_test,y_test X_test.to(device),y_test.to(device)model_0 model_0.to(device)forepochinrange(epochs):model_0.train()y_logits model_0(X_train).squeeze()y_pred torch.round(torch.sigmoid(y_logits))loss loss_fn(y_logits,y_train)acc accuracy_fn(y_true y_train,y_pred y_pred)optimizer.zero_grad()loss.backward()optimizer.step()model_0.eval()withtorch.inference_mode():test_logits model_0(X_test).squeeze()test_pred torch.round(torch.sigmoid(test_logits))test_loss loss_fn(test_logits,y_test)test_acc accuracy_fn(y_true y_test,y_pred test_pred)ifepoch%10 0:print(f\"{epoch}/{epochs}Loss:{loss:.5f},Accu:{acc:.2f}%TestLoss:{test_loss:.5f},TestAccu:{test_acc:.2f}%\")0/100 Loss: 0.70365, Accu: 49.88% Test Loss: 0.71542, Test Accu: 45.50% 10/100 Loss: 0.70059, Accu: 50.25% Test Loss: 0.71142, Test Accu: 45.00% 20/100 Loss: 0.69869, Accu: 50.38% Test Loss: 0.70858, Test Accu: 46.00% 30/100 Loss: 0.69740, Accu: 50.75% Test Loss: 0.70641, Test Accu: 46.00% 40/100 Loss: 0.69648, Accu: 50.75% Test Loss: 0.70469, Test Accu: 45.50% 50/100 Loss: 0.69580, Accu: 50.50% Test Loss: 0.70329, Test Accu: 46.50% 60/100 Loss: 0.69527, Accu: 50.75% Test Loss: 0.70214, Test Accu: 46.00% 70/100 Loss: 0.69487, Accu: 50.88% Test Loss: 0.70117, Test Accu: 45.50% 80/100 Loss: 0.69455, Accu: 50.75% Test Loss: 0.70036, Test Accu: 45.00% 90/100 Loss: 0.69429, Accu: 50.75% Test Loss: 0.69966, Test Accu: 45.00%模型看起来它很好地完成了训练和测试步骤，但结果似乎并没有太大的变化。每次数据分割时，准确率在50%左右。这是一个平衡的二进制分类问题，这意味着模型的性能与随机猜测差不多。##预测评估分类模型从指标来看，模型似乎是随机猜测。绘制一个模型预测的图，它试图预测的数据以及它为某个东西是类0还是类1创建的决策边界。为此，编写一些代码，一个名为`plot_decision_boundary()`的有用函数，该函数创建一个NumPymeshgrid，以可视化地绘制我们的模型预测某些类的不同点。importnumpyasnpdefplot_decision_boundary(model:torch.nn.Module,X:torch.Tensor,y:torch.Tensor):\"\"\"PlotsdecisionboundariesofmodelpredictingonXincomparisontoy.Source https://madewithml.com/courses/foundations/neural networks/(withmodifications)\"\"\"#PuteverythingtoCPU(worksbetterwithNumPy+Matplotlib)model.to(\"cpu\")X,y X.to(\"cpu\"),y.to(\"cpu\")#Setuppredictionboundariesandgridx_min,x_max X[:,0].min() 0.1,X[:,0].max()+0.1y_min,y_max X[:,1].min() 0.1,X[:,1].max()+0.1xx,yy np.meshgrid(np.linspace(x_min,x_max,101),np.linspace(y_min,y_max,101))#MakefeaturesX_to_pred_on torch.from_numpy(np.column_stack((xx.ravel(),yy.ravel()))).float()#Makepredictionsmodel.eval()withtorch.inference_mode():y_logits model(X_to_pred_on)#Testformulti classorbinaryandadjustlogitstopredictionlabelsiflen(torch.unique(y))>2:y_pred torch.softmax(y_logits,dim 1).argmax(dim 1)#mutli classelse:y_pred torch.round(torch.sigmoid(y_logits))#binary#Reshapepredsandploty_pred y_pred.reshape(xx.shape).detach().numpy()plt.contourf(xx,yy,y_pred,cmap plt.cm.RdYlBu,alpha 0.7)plt.scatter(X[:,0],X[:,1],c y,s 40,cmap plt.cm.RdYlBu)plt.xlim(xx.min(),xx.max())plt.ylim(yy.min(),yy.max())plt.figure(figsize (12,6))plt.subplot(1,2,1)plt.title(\"Train\")plot_decision_boundary(model_0,X_train,y_train)plt.subplot(1,2,2)plt.title(\"Test\")plot_decision_boundary(model_0,X_test,y_test)由图可知，模型目前正在尝试用直线分割红点和蓝点。由于我们的数据是圆形的，所以画一条直线最多只能把它从中间切开。在机器学习方面，模型是欠拟合的，这意味着它没有从数据中学习预测模式。##改进模型尝试解决模型的拟合不足问题。 专注于模型（而不是数据）。技巧作用: :: :增加更多隐藏层每一层都可能增加模型的学习能力，每一层都能够学习数据中的某种新模式。更多的层通常被称为使神经网络更深增加更多隐藏神经元与上面类似，每层更多的隐藏单元意味着模型学习能力的潜在增加。更多的隐藏单元通常被称为使你的神经网络更宽增加训练轮数如果模型训练更久，它可能会学到更多改变激活函数有些数据无法仅用直线拟合，使用非线性激活函数可以帮助解决这个问题改变学习率优化器的学习率决定了模型每一步应该改变多少参数，太多了模型会过度校正，太少了模型学习不足改变损失函数不同的问题需要不同的损失函数迁移学习从一个与问题领域相似的问题领域中提取一个预先训练好的模型，并根据问题进行调整###添加非线性classCircleModelV1(nn.Module):def__init__(self):super().__init__()self.layer_1 nn.Linear(in_features 2,out_features 10)self.layer_2 nn.Linear(in_features 10,out_features 10)self.layer_3 nn.Linear(in_features 10,out_features 1)self.relu nn.ReLU()defforward(self,x):returnself.layer_3(self.relu(self.layer_2(self.relu(self.layer_1(x)))))model_1 CircleModelV1().to(device)#model_1 nn.Sequential(#nn.Linear(2,10),#nn.ReLU(),#nn.Linear(10,10),#nn.ReLU(),#nn.Linear(10,1),#).to(device)model_1loss_fn nn.BCEWithLogitsLoss()optimizer torch.optim.SGD(params model_1.parameters(),lr 0.1)重新训练：torch.manual_seed(42)epochs 1500X_train,y_train X_train.to(device),y_train.to(device)X_test,y_test X_test.to(device),y_test.to(device)model_1.to(device)forepochinrange(epochs):model_1.train()y_logits model_1(X_train).squeeze()y_pred torch.round(torch.sigmoid(y_logits))loss loss_fn(y_logits,y_train)acc accuracy_fn(y_true y_train,y_pred y_pred)optimizer.zero_grad()loss.backward()optimizer.step()model_1.eval()withtorch.inference_mode():test_logits model_1(X_test).squeeze()test_pred torch.round(torch.sigmoid(test_logits))test_loss loss_fn(test_logits,y_test)test_acc accuracy_fn(y_true y_test,y_pred test_pred)ifepoch%100 0:print(f\"{epoch}/{epochs}Loss:{loss:.5f},Accu:{acc:.2f}%TestLoss:{test_loss:.5f},TestAccu:{test_acc:.2f}%\")0/1500 Loss: 0.69295, Accu: 50.00% Test Loss: 0.69319, Test Accu: 50.00% 100/1500 Loss: 0.69115, Accu: 52.88% Test Loss: 0.69102, Test Accu: 52.50% 200/1500 Loss: 0.68977, Accu: 53.37% Test Loss: 0.68940, Test Accu: 55.00% 300/1500 Loss: 0.68795, Accu: 53.00% Test Loss: 0.68723, Test Accu: 56.00% 400/1500 Loss: 0.68517, Accu: 52.75% Test Loss: 0.68411, Test Accu: 56.50% 500/1500 Loss: 0.68102, Accu: 52.75% Test Loss: 0.67941, Test Accu: 56.50% 600/1500 Loss: 0.67515, Accu: 54.50% Test Loss: 0.67285, Test Accu: 56.00% 700/1500 Loss: 0.66659, Accu: 58.38% Test Loss: 0.66322, Test Accu: 59.00% 800/1500 Loss: 0.65160, Accu: 64.00% Test Loss: 0.64757, Test Accu: 67.50% 900/1500 Loss: 0.62362, Accu: 74.00% Test Loss: 0.62145, Test Accu: 79.00% 1000/1500 Loss: 0.56818, Accu: 87.75% Test Loss: 0.57378, Test Accu: 86.50% 1100/1500 Loss: 0.48153, Accu: 93.50% Test Loss: 0.49935, Test Accu: 90.50% 1200/1500 Loss: 0.37056, Accu: 97.75% Test Loss: 0.40595, Test Accu: 92.00% 1300/1500 Loss: 0.25458, Accu: 99.00% Test Loss: 0.30333, Test Accu: 96.50% 1400/1500 Loss: 0.17180, Accu: 99.50% Test Loss: 0.22108, Test Accu: 97.50%可视化一下：plt.figure(figsize (12,6))plt.subplot(1,2,1)plt.title(\"Train\")plot_decision_boundary(model_1,X_train,y_train)plt.subplot(1,2,2)plt.title(\"Test\")plot_decision_boundary(model_1,X_test,y_test)现在模型的分类就有了显著的效果。##多分类问题###构建多分类数据集利用Scikit Learn的`make_blobs()`方法。这个方法将创建任意数量的类（使用`centers`参数）。1.使用`make_blobs()`创建一些多类数据。2.将数据转换为张量（`make_blobs()`的默认值是使用NumPy数组）。3.使用`train_test_split()`将数据拆分为训练集和测试集。4.可视化数据。importtorchimportmatplotlib.pyplotaspltfromsklearn.datasetsimportmake_blobsfromsklearn.model_selectionimporttrain_test_splitNUM_CLASSES 4NUM_FEATURES 2RANDOM_SEED 42X_blob,y_blob make_blobs(n_samples 1000,n_features NUM_FEATURES,centers NUM_CLASSES,cluster_std 1.5,random_state RANDOM_SEED)X_blob torch.from_numpy(X_blob).type(torch.float)y_blob torch.from_numpy(y_blob).type(torch.LongTensor)X_blob_train,X_blob_test,y_blob_train,y_blob_test train_test_split(X_blob,y_blob,test_size 0.2,random_state RANDOM_SEED)plt.figure(figsize (10,6))plt.scatter(X_blob[:,0],X_blob[:,1],c y_blob,cmap plt.cm.RdYlBu)###构建多元分类模型创建一个`nn.Module`的子类，接受三个超参数： `input_features`：输入特征的数量。 `output_features`：输出特征数（等效于`NUM_CLASSES`或多类分类问题中的类数）。 `hidden_units`：每个隐藏层使用的隐藏神经元的数量。device \"cuda\"iftorch.cuda.is_available()else\"cpu\"fromtorchimportnnclassBlobModel(nn.Module):def__init__(self,input_features,output_features,hidden_units 8):super().__init__()self.model nn.Sequential(nn.Linear(in_features input_features,out_features hidden_units),nn.ReLU(),nn.Linear(in_features hidden_units,out_features hidden_units),nn.ReLU(),nn.Linear(in_features hidden_units,out_features output_features))defforward(self,x):returnself.model(x)model_2 BlobModel(input_features NUM_FEATURES,output_features NUM_CLASSES,hidden_units 8).to(device)model_2###构建多元分类损失函数和优化器loss_fn nn.CrossEntropyLoss()optimizer torch.optim.SGD(model_2.parameters(),lr 0.1)试着看看模型前向输出：y_logits model_2(X_blob_train.to(device))[:5]y_logits再看看经过激活函数Softmax之后的结果：y_pred_probs torch.softmax(y_logits,dim 1)y_pred_probs经过Softmax函数之后，先前的数字变成预测到某类的概率。这些预测概率本质上是说模型认为目标样本（输入）映射到每个类的程度。由于y_pred_probs中的每个类都有一个值，因此最高值的索引是模型认为特定数据样本最属于的类。可以使用`torch.argmax()`检查哪个索引具有最高值。torch.argmax(y_pred_probs[0])###构建多分类训练和测试循环torch.manual_seed(42)epochs 100X_blob_train,y_blob_train X_blob_train.to(device),y_blob_train.to(device)X_blob_test,y_blob_test X_blob_test.to(device),y_blob_test.to(device)model_2.to(device)forepochinrange(epochs):model_2.train()y_logits model_2(X_blob_train)y_pred torch.softmax(y_logits,dim 1).argmax(dim 1)loss loss_fn(y_logits,y_blob_train)acc accuracy_fn(y_true y_blob_train,y_pred y_pred)optimizer.zero_grad()loss.backward()optimizer.step()model_2.eval()withtorch.inference_mode():test_logits model_2(X_blob_test)test_pred torch.softmax(test_logits,dim 1).argmax(dim 1)test_loss loss_fn(test_logits,y_blob_test)tess_acc accuracy_fn(y_true y_blob_test,y_pred test_pred)ifepoch%10 0:print(f\"{epoch}/{epochs}Loss:{loss:.5f},Acc:{acc:.2f}%TestLoss:{test_loss:.5f},TestAcc:{test_acc:.2f}%\")0/100 Loss: 1.15883, Acc: 40.38% Test Loss: 1.07554, Test Acc: 99.00% 10/100 Loss: 0.64476, Acc: 96.75% Test Loss: 0.66069, Test Acc: 99.00% 20/100 Loss: 0.42535, Acc: 98.50% Test Loss: 0.43074, Test Acc: 99.00% 30/100 Loss: 0.25294, Acc: 99.12% Test Loss: 0.24508, Test Acc: 99.00% 40/100 Loss: 0.11232, Acc: 99.25% Test Loss: 0.10229, Test Acc: 99.00% 50/100 Loss: 0.06627, Acc: 99.25% Test Loss: 0.05848, Test Acc: 99.00% 60/100 Loss: 0.05068, Acc: 99.25% Test Loss: 0.04293, Test Acc: 99.00% 70/100 Loss: 0.04300, Acc: 99.25% Test Loss: 0.03491, Test Acc: 99.00% 80/100 Loss: 0.03836, Acc: 99.25% Test Loss: 0.02988, Test Acc: 99.00% 90/100 Loss: 0.03525, Acc: 99.25% Test Loss: 0.02663, Test Acc: 99.00%###评估多分类模型使用准确率评估：model_2.eval()withtorch.inference_mode():y_logits model_2(X_blob_test)y_preds torch.softmax(y_logits,dim 1).argmax(dim 1)print(f\"Testaccuracy:{accuracy_fn(y_true y_blob_test,y_pred y_preds)}%\")Test accuracy: 99.5%可视化评估：plt.figure(figsize (12,6))plt.subplot(1,2,1)plt.title(\"Train\")plot_decision_boundary(model_2,X_blob_train,y_blob_train)plt.subplot(1,2,2)plt.title(\"Test\")plot_decision_boundary(model_2,X_blob_test,y_blob_test)##更多分类评估指标评估指标定义代码: :: :: :正确率模型预测正确的占比`torchmetrics.Accuracy()`或`sklearn.metrics.accuracy_score()`精确率$\\text{Precision} \\frac{TP}{TP+FP}$`torchmetrics.Precision()`或`sklearn.metrics.precision_score()`召回率$\\text{Recall} \\frac{TP}{TP+FN}$`torchmetrics.Recall()`或`sklearn.metrics.recall_score()`F1 Score将查准率和查全率合并为一个指标。1是最好的，0是最坏的`torchmetrics.F1Score()`或`sklearn.metrics.f1_score()`混淆矩阵以表格方式将预测值与真实值进行比较，如果100%正确，矩阵中的所有值将从左上角到右下角（对角线）`torchmetrics.ConfusionMatrix`或`sklearn.metrics.plot_confusion_matrix()`分类报告一些主要分类指标的集合，如精度，召回率和f1分数`sklearn.metrics.classification_report()`"},"/StyleTransfer/ref_and_notes/pytorch_computer_vision.html":{"title":"计算机视觉基础","content":"Reference:[PyTorchComputerVision](https://www.learnpytorch.io/03_pytorch_computer_vision/)*该页面由JupyterNotebook生成，原文件于[Github](https://github.com/Fingsinz/StyleTransfer/tree/main/src/02.pytorch_learning/pytorch_computer_vision.ipynb)*##PyTorch的计算机视觉库PyTorch中关于计算机视觉的库有：模块作用: :: :[torchvision](https://pytorch.org/vision/stable/index.html)包含通常用于计算机视觉问题的数据集、模型架构和图像转换[torchvision.datasets](https://pytorch.org/vision/stable/datasets.html)包含许多计算机视觉数据集，用于解决图像分类、对象检测、图像字幕、视频分类等一系列问题，还包含一系列用于创建自定义数据集的基类[torchvision.models](https://pytorch.org/vision/stable/models.html)包含在PyTorch中实现的性能良好且常用的计算机视觉模型架构，可以将其用于解决问题[torchvision.transforms](https://pytorch.org/vision/stable/transforms.html)图像需要在与模型一起使用之前进行预处理（转换为数字/处理/增强），包含常见的图像转换[torch.utils.data.Dataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset)PyTorch基础数据集类[torch.utils.data.DataLoader](https://pytorch.org/docs/stable/data.html#module torch.utils.data)创建一个可在数据集上迭代的对象（`torch.utils.data.Dataset`）#PyTorchimporttorchfromtorchimportnn#torchvisionimporttorchvisionfromtorchvisionimportdatasetsfromtorchvision.transformsimportToTensor#matplotlibimportmatplotlib.pyplotaspltprint(f\"{torch.__version__}\\n{torchvision.__version__}\")2.5.1+cu124 0.20.1+cu124device \"cuda\"iftorch.cuda.is_available()else\"cpu\"device##准备数据集`torchvision.datasets`包含了大量的示例数据集，可以使用它们来练习编写计算机视觉代码。 MNIST：手写数字数据集，包含数千个手写数字（从0到9）的示例。 FashionMNIST：有10个不同的图像类（不同类型的衣服），这是一个多类分类问题。FashionMNIST可以通过`torchvision.datasets.FashionMNIST`获得。提供以下参数： `root:str`，数据下载到哪个文件夹； `train:Bool`，训练还是测试分割； `download:Bool`，是否下载数据； `transform:torchvision.transforms`，对数据的转换； `target_transform`，对目标（标签）的转换。train_data datasets.FashionMNIST(root \"data\",train True,download True,transform ToTensor(),#图像以PIL格式出现，将其转换为Torch张量target_transform None)test_data datasets.FashionMNIST(root \"data\",train False,#表示测试download True,transform ToTensor())len(train_data),len(test_data)###了解数据集得到数据后，需要了解数据的Shape：image,label train_data[0]image.shape图像张量的形状是`[1，28，28]`或更具体地：`[color_channels 1，height 28，width 28]`。不同的问题会有不同的输入和输出形式。但前提仍然是将数据编码成数字，建立一个模型来找到这些数字中的模式，将这些模式表达成有意义的东西。>除了CHW（通道，高度，宽度）表示，后续还会见到NCHW和NHWC格式，其中N代表图像数量。例如，当batch_size 32，则张量形状可能是[32，1，28，28]。>>PyTorch通常接受NCHW（通道优先）作为许多操作的默认设置。然而，PyTorch还解释说，NHWC（通道最后）性能更好，被认为是最佳实践。>>由于目前的数据集和模型相对较小，这不会有太大的区别。了解数据集的数量后，还可以了解一下类别属性：class_names train_data.classesclass_names可以可视化一下数据：image,label train_data[0]plt.figure(figsize (4,4))plt.imshow(image.squeeze(),cmap \"gray\")#Shape为[1,28,28]，将通道挤压一下plt.title(label)查看更多：torch.manual_seed(42)fig plt.figure(figsize (7,7))rows,cols 4,4foriinrange(1,rows*cols+1):random_idx torch.randint(0,len(train_data),size [1]).item()img,label train_data[random_idx]fig.add_subplot(rows,cols,i)plt.imshow(img.squeeze(),cmap \"gray\")plt.title(class_names[label])plt.axis(False)###构建DataLoader现在已经有了一个数据集，下一步是用`torch.utils.data.DataLoader`准备它。DataLoader有助于将数据加载到模型中。为了训练和推理，它将一个大的数据集转换成一个可迭代的小块。 这些较小的块称为批处理或小批处理，可以通过`batch_size`参数进行设置，这样做可以让计算效率更高。对于小批量（数据的一小部分）而言，每个epoch执行梯度下降的频率更高。 每个batch一次，而不是每个epoch一次。`batch_size`是一个超参数，视情况而定。通常使用2的幂（例如32、64、128、256、512）。fromtorch.utils.dataimportDataLoaderBATCH_SIZE 32train_dataloader DataLoader(train_data,batch_size BATCH_SIZE,shuffle True#每一个epoch都洗牌数据)test_dataloader DataLoader(test_data,batch_size BATCH_SIZE,shuffle False)print(f\"Train:{len(train_dataloader)}\")print(f\"Test:{len(test_dataloader)}\")Train: 1875 Test: 313看看每个batch的shape：train_features_batch,train_labels_batch next(iter(train_dataloader))train_features_batch.shape,train_labels_batch.shape##模型0：构建基线模型数据已加载并准备就绪。基线模型是最简单的模型之一。使用基线作为起点，并尝试使用后续的更复杂的模型对其进行改进。目前基线模型将由两个`nn.Linear()`层组成。因为这是图像数据，所以将使用`nn.Flatten()`层开始。 `nn.Flatten()`将张量的维度压缩为单个向量。classFashionMNISTModelV0(nn.Module):def__init__(self,input_shape:int,hidden_units:int,output_shape:int):super().__init__()self.model nn.Sequential(nn.Flatten(),nn.Linear(in_features input_shape,out_features hidden_units),nn.Linear(in_features hidden_units,out_features output_shape))defforward(self,x):returnself.model(x)设置以下参数： `input_shape 784`：此例中，目标图像中的每个像素都有一个特征（28像素高×28像素宽 784个特征）。 `hidden_units 10`：隐藏层中的神经元数量。 `output_shape len(class_names)`：多分类问题，需要为数据集中的每个类提供一个输出神经元。torch.manual_seed(42)model_0 FashionMNISTModelV0(input_shape 784,hidden_units 10,output_shape len(class_names))设置上损失函数和优化器：loss_fn nn.CrossEntropyLoss()optimizer torch.optim.SGD(params model_0.parameters(),lr 0.1)自定义计算准确率的函数和计时函数：defaccuracy_fn(y_true,y_pred):correct torch.eq(y_true,y_pred).sum().item()acc (correct/len(y_pred))*100returnaccfromtimeitimportdefault_timerastimerdefprint_train_time(start:float,end:float,device:torch.device None):total_time end startprint(f\"{device}:{total_time:.3f}seconds\")returntotal_time构建训练和测试循环（CPU）：torch.manual_seed(42)train_time_start timer()epochs 3forepochinrange(epochs):print(f\"Epoch:{epoch}\\n \")train_loss 0forbatch,(X,y)inenumerate(train_dataloader):model_0.train()y_pred model_0(X)loss loss_fn(y_pred,y)train_loss+ lossoptimizer.zero_grad()loss.backward()optimizer.step()train_loss/ len(train_dataloader)test_loss,test_acc 0,0model_0.eval()withtorch.inference_mode():forX,yintest_dataloader:test_pred model_0(X)test_loss+ loss_fn(test_pred,y)test_acc+ accuracy_fn(y_true y,y_pred test_pred.argmax(dim 1))test_loss/ len(test_dataloader)test_acc/ len(test_dataloader)print(f\"\\n训练loss:{train_loss:.5f}测试loss:{test_loss:.5f},测试acc:{test_acc:.2f}%\\n\")train_time_end timer()total_train_time_model_0 print_train_time(start train_time_start,end train_time_end,device str(next(model_0.parameters()).device))Epoch: 0 训练 loss: 0.59039 测试 loss: 0.50954, 测试 acc: 82.04% Epoch: 1 训练 loss: 0.47633 测试 loss: 0.47989, 测试 acc: 83.20% Epoch: 2 训练 loss: 0.45503 测试 loss: 0.47664, 测试 acc: 83.43% cpu: 37.968 seconds##模型0：预测与评估创建一个函数，接受一个训练过的模型，一个DataLoader，一个损失函数和一个精度函数，使用模型对DataLoader中的数据进行预测，然后使用损失函数和精度函数来评估这些预测。torch.manual_seed(42)defeval_model(model:torch.nn.Module,data_loader:torch.utils.data.DataLoader,loss_fn:torch.nn.Module,accuracy_fn,device:torch.device device):\"\"\"Evaluatesagivenmodelonagivendataset.Args:model(torch.nn.Module):APyTorchmodelcapableofmakingpredictionsondata_loader.data_loader(torch.utils.data.DataLoader):Thetargetdatasettopredicton.loss_fn(torch.nn.Module):Thelossfunctionofmodel.accuracy_fn:Anaccuracyfunctiontocomparethemodelspredictionstothetruthlabels.device(str,optional):Targetdevicetocomputeon.Defaultstodevice.Returns:(dict):Resultsofmodelmakingpredictionsondata_loader.\"\"\"loss,acc 0,0model.eval()withtorch.inference_mode():forX,yindata_loader:#SenddatatothetargetdeviceX,y X.to(device),y.to(device)y_pred model(X)loss+ loss_fn(y_pred,y)acc+ accuracy_fn(y_true y,y_pred y_pred.argmax(dim 1))#Scalelossandaccloss/ len(data_loader)acc/ len(data_loader)return{\"model_name\":model.__class__.__name__,#onlyworkswhenmodelwascreatedwithaclass\"model_loss\":loss.item(),\"model_acc\":acc}#Calculatemodel0resultsontestdatasetmodel_0_results eval_model(model model_0,data_loader test_dataloader,loss_fn loss_fn,accuracy_fn accuracy_fn,device str(next(model_0.parameters()).device))model_0_results##模型1：添加非线性classFashionMNISTModelV1(nn.Module):def__init__(self,input_shape:int,hidden_units:int,output_shape:int):super().__init__()self.model nn.Sequential(nn.Flatten(),nn.Linear(in_features input_shape,out_features hidden_units),nn.ReLU(),nn.Linear(in_features hidden_units,out_features output_shape),nn.ReLU())defforward(self,x:torch.Tensor):returnself.model(x)接着实例化：torch.manual_seed(42)model_1 FashionMNISTModelV1(input_shape 784,hidden_units 10,output_shape len(class_names)).to(device)next(model_1.parameters()).device再次设置损失函数和优化器：loss_fn nn.CrossEntropyLoss()optimizer torch.optim.SGD(params model_1.parameters(),lr 0.1)将训练过程封装成函数：deftrain_step(model:torch.nn.Module,data_loader:torch.utils.data.DataLoader,loss_fn:torch.nn.Module,optimizer:torch.optim.Optimizer,accuracy_fn,device:torch.device device):train_loss,train_acc 0,0model.to(device)forbatch,(X,y)inenumerate(data_loader):#SenddatatoGPUX,y X.to(device),y.to(device)y_pred model(X)loss loss_fn(y_pred,y)train_loss+ losstrain_acc+ accuracy_fn(y_true y,y_pred y_pred.argmax(dim 1))optimizer.zero_grad()loss.backward()optimizer.step()train_loss/ len(data_loader)train_acc/ len(data_loader)print(f\"训练loss:{train_loss:.5f}训练accuracy:{train_acc:.2f}%\")deftest_step(data_loader:torch.utils.data.DataLoader,model:torch.nn.Module,loss_fn:torch.nn.Module,accuracy_fn,device:torch.device device):test_loss,test_acc 0,0model.to(device)model.eval()withtorch.inference_mode():forX,yindata_loader:X,y X.to(device),y.to(device)test_pred model(X)test_loss+ loss_fn(test_pred,y)test_acc+ accuracy_fn(y_true y,y_pred test_pred.argmax(dim 1))test_loss/ len(data_loader)test_acc/ len(data_loader)print(f\"Testloss:{test_loss:.5f}Testaccuracy:{test_acc:.2f}%\\n\")然后调用函数：torch.manual_seed(42)train_time_start timer()epochs 3forepochinrange(epochs):print(f\"Epoch:{epoch}\\n \")train_step(data_loader train_dataloader,model model_1,loss_fn loss_fn,optimizer optimizer,accuracy_fn accuracy_fn)test_step(data_loader test_dataloader,model model_1,loss_fn loss_fn,accuracy_fn accuracy_fn)train_time_end timer()total_train_time_model_1 print_train_time(start train_time_start,end train_time_end,device device)Epoch: 0 训练 loss: 1.09199 训练 accuracy: 61.34% Test loss: 0.95636 Test accuracy: 65.00% Epoch: 1 训练 loss: 0.78101 训练 accuracy: 71.93% Test loss: 0.72227 Test accuracy: 73.91% Epoch: 2 训练 loss: 0.67027 训练 accuracy: 75.94% Test loss: 0.68500 Test accuracy: 75.02% cuda: 40.312 seconds>注意：CUDA与CPU的训练时间在很大程度上取决于您使用的CPU/GPU的质量。>问题：“我使用了GPU，但我的模型没有更快地训练，为什么会这样？\">>答：一个原因可能是因为你的数据集和模型都很小（就像此例子正在使用的数据集和模型一样），使用GPU的好处被传输数据所花费的时间所抵消。在将数据从CPU内存（默认）复制到GPU内存之间存在一个小瓶颈。因此，对于较小的模型和数据集，CPU实际上可能是计算的最佳位置。对于较大的数据集和模型，GPU可以提供的计算速度通常远远超过获取数据的成本。但是，这在很大程度上取决于您使用的硬件。来评估一下模型：torch.manual_seed(42)model_1_results eval_model(model model_1,data_loader test_dataloader,loss_fn loss_fn,accuracy_fn accuracy_fn,device device)model_0_results,model_1_results在这种情况下，看起来向模型添加非线性使它的性能比基线模型更差。从事物的外观来看，模型似乎对训练数据过度拟合。过度拟合意味着我们的模型很好地学习了训练数据，但这些模式并没有推广到测试数据。修复过拟合的两种主要方法包括： 使用较小或不同的模型（某些模型比其他模型更适合某些类型的数据）。 使用更大的数据集（数据越多，模型学习可推广模式的机会就越大）。##模型2：CNN卷积神经网络的典型结构：`输入层 >[卷积层 >激活层 >池化层] >输出层` 其中，`[卷积层 >激活层 >池化层]`的内容可以根据要求放大和重复多次。下表是一个很好的通用指南，可以指导使用哪种模型（尽管也有例外）。类型一般使用模型示例: :: :: :结构化数据（如表格、行、列数据）梯度提升模型，随机森林，XGBoost`sklearn.ensemble`，`XGBoostlibrary`非结构化数据（如图像、音频、语言）卷积神经网络，Transformers`torchvision.models`，`HuggingFaceTransformers`使用`torch.nn`中的`nn.Conv2d()`和`nn.MaxPool2d()`层：classFashionMNISTModelV2(nn.Module):\"\"\"ModelarchitecturecopyingTinyVGGfrom:https://poloclub.github.io/cnn explainer/\"\"\"def__init__(self,input_shape:int,hidden_units:int,output_shape:int):super().__init__()self.block_1 nn.Sequential(nn.Conv2d(in_channels input_shape,out_channels hidden_units,kernel_size 3,#卷积核大小stride 1,#defaultpadding 1),#\"valid\"（无填充），\"same\"（输出与输入具有相同的形状），int表示特定的数字nn.ReLU(),nn.Conv2d(in_channels hidden_units,out_channels hidden_units,kernel_size 3,stride 1,padding 1),nn.ReLU(),nn.MaxPool2d(kernel_size 2,stride 2)#默认stride与池化窗口大小一致)self.block_2 nn.Sequential(nn.Conv2d(hidden_units,hidden_units,3,padding 1),nn.ReLU(),nn.Conv2d(hidden_units,hidden_units,3,padding 1),nn.ReLU(),nn.MaxPool2d(2))self.classifier nn.Sequential(nn.Flatten(),#这个in_features形状是是因为网络的每一层都会压缩和改变我们输入数据的形状。#此例中28*28池化一次变成14*14，再池化变成7*7nn.Linear(in_features hidden_units*7*7,out_features output_shape))defforward(self,x:torch.Tensor):x self.block_1(x)x self.block_2(x)x self.classifier(x)returnxtorch.manual_seed(42)model_2 FashionMNISTModelV2(input_shape 1,hidden_units 10,output_shape len(class_names)).to(device)model_2*该笔记只讲代码，不讲原理。*设置损失函数与优化器：loss_fn nn.CrossEntropyLoss()optimizer torch.optim.SGD(params model_2.parameters(),lr 0.1)进行训练：torch.manual_seed(42)train_time_start_model_2 timer()epochs 3forepochinrange(epochs):print(f\"Epoch:{epoch}\\n \")train_step(data_loader train_dataloader,model model_2,loss_fn loss_fn,optimizer optimizer,accuracy_fn accuracy_fn,device device)test_step(data_loader test_dataloader,model model_2,loss_fn loss_fn,accuracy_fn accuracy_fn,device device)train_time_end_model_2 timer()total_train_time_model_2 print_train_time(start train_time_start_model_2,end train_time_end_model_2,device device)Epoch: 0 训练 loss: 0.59430 训练 accuracy: 78.44% Test loss: 0.40483 Test accuracy: 85.33% Epoch: 1 训练 loss: 0.36487 训练 accuracy: 86.81% Test loss: 0.35013 Test accuracy: 87.23% Epoch: 2 训练 loss: 0.32794 训练 accuracy: 88.12% Test loss: 0.31522 Test accuracy: 88.63% cuda: 52.375 seconds看起来效果甚好。model_2_results eval_model(model model_2,data_loader test_dataloader,loss_fn loss_fn,accuracy_fn accuracy_fn,device device)model_2_results##比较并评估模型这里训练了三个模型： `model_0`：具有两个`nn.Linear()`层的基线模型。 `model_1`：与基线模型相同，除了在`nn.Linear()`层之间有`nn.ReLU()`层。 `model_2`：CNN模型，模仿CNNExplainer网站上的TinyVGG架构。使用`pandas`的`DataFrame`将数据展示：importpandasaspdcompare_results pd.DataFrame([model_0_results,model_1_results,model_2_results])compare_results[\"training_time\"] [total_train_time_model_0,total_train_time_model_1,total_train_time_model_2]compare_results结论： CNN（FashionMNISTModelV2）模型表现最好（损失最低，准确率最高），但训练时间最长。 基线模型（FashionMNISTModelV0）的性能优于model_1（FashionMNISTModelV1）。比较可视化：plt.figure(figsize (4,4))compare_results.set_index(\"model_name\")[\"model_acc\"].plot(kind \"barh\")plt.xlabel(\"accuracy(%)\")plt.ylabel(\"model\")可以使用许多不同的评估指标来解决分类问题，其中最直观的是混淆矩阵。混淆矩阵显示了分类模型在预测和真实标签之间混淆的地方。制作混淆矩阵：1.使用训练模型进行预测（混淆矩阵将预测与真实标签进行比较）。2.使用`torchmetrics.ConfusionMatrix`制作混淆矩阵。3.使用`mlxtend.plotting.plot_confusion_matrix()`绘制混淆矩阵。#1.使用训练模型进行预测y_preds []model_2.eval()withtorch.inference_mode():forX,yintest_dataloader:X,y X.to(device),y.to(device)y_logit model_2(X)y_pred torch.softmax(y_logit,dim 1).argmax(dim 1)y_preds.append(y_pred.cpu())y_pred_tensor torch.cat(y_preds)下载并导入`torchmetrics`和`mlxtend`：fromtorchmetricsimportConfusionMatrixfrommlxtend.plottingimportplot_confusion_matrix#2.设置混淆矩阵实例并将预测与目标进行比较confmat ConfusionMatrix(num_classes len(class_names),task 'multiclass')confmat_tensor confmat(preds y_pred_tensor,target test_data.targets)#3.绘图fig,ax plot_confusion_matrix(conf_mat confmat_tensor.numpy(),#matplotlib就像NumPy一样class_names class_names,#将行和列标签转换为类名figsize (4,4))可以看到模型表现相当好，因为大多数黑色方块对角线（理想模型将只在这些方块中有值，其他地方都是0）。混淆矩阵的信息能够进一步检查模型和数据，看看如何改进。"},"/StyleTransfer/ref_and_notes/pytorch_custom_datasets.html":{"title":"自定义数据集","content":"Reference:[PyTorchCustomDatasets](https://www.learnpytorch.io/04_pytorch_custom_datasets/)*该页面由JupyterNotebook生成，原文件于[Github](https://github.com/Fingsinz/StyleTransfer/tree/main/src/02.pytorch_learning/pytorch_custom_datasets.ipynb)*#导入包和设置设备importtorchfromtorchimportnndevice \"cuda\"iftorch.cuda.is_available()else\"cpu\"torch.__version__,device##获取并处理数据###获取数据首先，需要一些数据。这里使用的数据是[Food101数据集](https://data.vision.ee.ethz.ch/cvl/datasets_extra/food 101/)的一个子集。 Food101包含101种不同食物的1000张图像，总计101000张图像（75750张训练图像和25250张测试图像）。为了自定义数据集，选取将3种食物开始：披萨、牛排和寿司。同时每个类并不是1000个图像，而是从随机的10%开始（从小处开始，必要时增加）。可以以下步骤下载数据集： 原始Food101数据集和论文网站。 笔记本（https://www.learnpytorch.io）提供。importrequestsimportzipfilefrompathlibimportPath#Setuppathtodatafolderdata_path Path(\"data/\")image_path data_path/\"pizza_steak_sushi\"#Iftheimagefolderdoesn'texist,downloaditandprepareit...ifimage_path.is_dir():print(f\"{image_path}directoryexists.\")else:print(f\"Didnotfind{image_path}directory,creatingone...\")image_path.mkdir(parents True,exist_ok True)#Downloadpizza,steak,sushidatawithopen(data_path/\"pizza_steak_sushi.zip\",\"wb\")asf:request requests.get(\"https://github.com/mrdbourke/pytorch deep learning/raw/main/data/pizza_steak_sushi.zip\")print(\"Downloadingpizza,steak,sushidata...\")f.write(request.content)#Unzippizza,steak,sushidatawithzipfile.ZipFile(data_path/\"pizza_steak_sushi.zip\",\"r\")aszip_ref:print(\"Unzippingpizza,steak,sushidata...\")zip_ref.extractall(image_path)data\\pizza_steak_sushi directory exists.*也可以自行下载数据集，并划分为train和test。*在此例中，有标准图像分类格式的披萨、牛排和寿司图像。图像分类格式在单独的目录中包含单独的图像类，标题为特定的类名。例如，pizza的所有图像都包含在pizza/目录中。```pizza_steak_sushi/train/pizza/steak/sushi/test/pizza/steak/sushi/```目标是将这个数据存储结构转化为PyTorch可用的数据集。现在试着打开几张图片看看：1.使用`pathlib.Path.glob()`获取所有图像路径，以查找所有以`.jpg`结尾的文件。2.使用Python的`random.choice()`选择一个随机的图像路径。3.使用`pathlib.Path.parent.stem`获取图像类名。4.使用`PIL.image.open()`（PIL代表PythonimageLibrary）打开随机图像路径。5.显示图像并打印一些元数据。importrandomfromPILimportImagerandom.seed(42)image_path_list list(image_path.glob(\"*/*/*.jpg\"))random_image_path random.choice(image_path_list)image_class random_image_path.parent.stemimg Image.open(random_image_path)print(f\"Randomimagepath:{random_image_path}\")print(f\"Imageclass:{image_class}\")print(f\"Imageheight:{img.height}\")print(f\"Imagewidth:{img.width}\")imgRandom image path: data\\pizza_steak_sushi\\test\\sushi\\2394442.jpg Image class: sushi Image height: 408 Image width: 512同样可以使用`matplotlib`：importnumpyasnpimportmatplotlib.pyplotaspltimg_as_array np.asarray(img)plt.figure(figsize (5,5))plt.imshow(img_as_array)plt.title(f\"Imageclass:{image_class}Imageshape:{img_as_array.shape} >[height,width,color_channels]\")plt.axis(False);###转化数据集表示现在希望将图像数据加载到PyTorch中。在PyTorch中使用图像数据之前，需要：1.把它变成张量（图像的数值表示）。2.将其转换为`torch.utils.data.dataset`，随后再转换为`torch.utils.data.DataLoader`，简称它们为Dataset和DataLoader。PyTorch有几种不同类型的预构建数据集和数据集加载器，具体取决于处理的问题。 视觉类：`torchvision.datasets`； 音频类：`torchaudio.datasets`； 文本类：`torchtext.datasets`； 推荐系统：`torchrec.datasets`。#导入包importtorchfromtorch.utils.dataimportDataLoaderfromtorchvisionimportdatasets,transforms使用`torchvision.transforms`转化数据：1.使用`transform.Resize()`调整图像的大小。2.使用`transform.RandomHorizontalFlip()`在水平方向上随机翻转图像（这可以被认为是一种数据增强形式，因为它会人为地改变我们的图像数据）。3.使用`transform.ToTensor()`将图像从PIL图像转换为PyTorch张量。可以使用`torchvision.transforms.Compose()`编译所有这些步骤。data_transform transforms.Compose([transforms.Resize(size (64,64)),transforms.RandomHorizontalFlip(p 0.5),#p为翻转的概率transforms.ToTensor()])接下来试试转换的效果：defplot_transformed_images(image_paths,transform,n 3,seed 42):random.seed(seed)random_image_paths random.sample(image_paths,k n)forimage_pathinrandom_image_paths:withImage.open(image_path)asf:fig,ax plt.subplots(1,2)ax[0].imshow(f)ax[0].set_title(f\"Original\\nSize:{f.size}\")ax[0].axis(\"off\")#permute()会改变图像的形状以适应matplotlib#(PyTorchdefaultis[C,H,W]butMatplotlibis[H,W,C])transformed_image transform(f).permute(1,2,0)ax[1].imshow(transformed_image)ax[1].set_title(f\"Transformed\\nSize:{transformed_image.shape}\")ax[1].axis(\"off\")fig.suptitle(f\"Class:{image_path.parent.stem}\",fontsize 16)plot_transformed_images(image_path_list,transform data_transform,n 3)##使用ImageFolder加载数据目前数据是标准的图像分类格式，所以可以使用`torchvision.datasets.ImageFolder`类。将目标图像目录的文件路径以及我们想要对图像执行的一系列转换传递给它。fromtorchvisionimportdatasetstrain_dir image_path/\"train\"test_dir image_path/\"test\"train_data datasets.ImageFolder(root train_dir,transform data_transform,target_transform None)#转换在标签上执行test_data datasets.ImageFolder(root test_dir,transform data_transform)print(f\"Traindata:\\n{train_data}\\nTestdata:\\n{test_data}\")Train data: Dataset ImageFolder Number of datapoints: 225 Root location: data\\pizza_steak_sushi\\train StandardTransform Transform: Compose( Resize(size (64, 64), interpolation bilinear, max_size None, antialias True) RandomHorizontalFlip(p 0.5) ToTensor() ) Test data: Dataset ImageFolder Number of datapoints: 75 Root location: data\\pizza_steak_sushi\\test StandardTransform Transform: Compose( Resize(size (64, 64), interpolation bilinear, max_size None, antialias True) RandomHorizontalFlip(p 0.5) ToTensor() )现在PyTorch已经注册了数据集。通过检查`classes`和`class_to_idx`属性以及训练集和测试集的长度来检查一下：class_names train_data.classesclass_dict train_data.class_to_idxclass_names,class_dict,len(train_data),len(test_data)再检查一下训练数据和测试数据：img,label train_data[0][0],train_data[0][1]img.shape,img.dtype,label,type(label)图像现在是张量的形式（形状为`[3,64,64] >[通道,高度,宽度]`），标签是与特定类相关的整数形式（由class_to_idx属性引用）。还需要将数据转换为DataLoader。将Dataset转换为DataLoader，模型可以遍历并学习样本和目标（特征和标签）之间的关系。为了简单起见，将使用`batch_size 1`和`num_workers 1`。 `batch_size`已经解释过，批量大小。 `num_workers`定义将创建多少个子进程来加载数据，`num_workers`设置的值越高，PyTorch在加载数据时使用的计算能力就越强。通常通过Python的`os.cpu_count()`将其设置为CPU总数，确保DataLoader使用尽可能多的内核来加载数据。fromtorch.utils.dataimportDataLoadertrain_dataloader DataLoader(dataset train_data,batch_size 1,num_workers 1,shuffle True)test_dataloader DataLoader(dataset test_data,batch_size 1,num_workers 1,shuffle False)最后获取`train_dataloader`中每个可迭代项的Shape信息：img,label next(iter(train_dataloader))img.shape,label.shape##使用自定义DataSet类加载数据如果像`torchvision.datasets.ImageFolder()`这样的预构建数据集创建器不存在，或者针对具体问题的解决方案根本不存在，那么可以自定义一个。创建自定义方式来加载Dataset的优缺点： 优点：可以用几乎任何东西创建数据集，不限于PyTorch预构建的Dataset函数。 缺点：尽管可以用几乎任何东西创建一个数据集，但这并不意味着它就有效；同时会导致编写更多代码，这可能容易出现错误或性能问题。实际操作是继承`torch.utils.data.Dataset`（PyTorch中所有Dataset的基类）来复制`torchvision.datasets.ImageFolder()`。从导入需要的模块开始： Python处理目录的`os`（数据存储在目录中）。 Python处理文件路径的`pathlib`（每个图像都有一个唯一的文件路径）。 PyTorch的所有的东西。 用于加载图像的PIL的Image类。 继承`torch.utils.data.Dataset`创建自定义数据集。 `torchvision.transforms`把图像变成张量。 来自Python的typing模块的各种类型，为代码添加类型提示。importosimportpathlibimporttorchfromPILimportImagefromtorch.utils.dataimportDatasetfromtorchvisionimporttransformsfromtypingimportTuple,Dict,List###获取数据类名首先实现获取数据类名的函数，获取如`['pizza','steak','sushi'],{'pizza':0,'steak':1,'sushi':2}`的信息：deffind_classes(directory:str) >Tuple[List[str],Dict[str,int]]:\"\"\"Findstheclassfoldernamesinatargetdirectory.Assumestargetdirectoryisinstandardimageclassificationformat.Args:directory(str):targetdirectorytoloadclassnamesfrom.Returns:Tuple[List[str],Dict[str,int]]:(list_of_class_names,dict(class_name:idx...))Example:find_classes(\"food_images/train\")>>>([\"class_1\",\"class_2\"],{\"class_1\":0,...})\"\"\"#1.通过扫描目标目录获取类名classes sorted(entry.nameforentryinos.scandir(directory)ifentry.is_dir())#2.如果找不到类名，则引发错误ifnotclasses:raiseFileNotFoundError(f\"Couldn'tfindanyclassesin{directory}.\")#3.创建索引标签的字典class_to_idx {cls_name:ifori,cls_nameinenumerate(classes)}returnclasses,class_to_idx测试一下：find_classes(train_dir)###构建自定义数据集类将构建一个类来复刻`torchvision.datasets.ImageFolder()`的功能。分析如下：1.继承`torch.utils.data.Dataset`。2.用`targ_dir`参数（目标数据目录）和`transform`参数初始化子类。3.创建属性：目标图像路径、`transform`（可以是`None`），`classes`和`class_to_idx`（来自`find_classes()`函数）。4.创建一个函数从文件中加载图像并返回它们，可以使用`PIL`或`torchvision.io`。5.重写`torch.utils.data.Dataset`的`__len__`方法，返回数据集中的样本数量。（不必需）6.重写`torch.utils.data.Dataset`的`__getitem__`方法以返回数据集中的单个样本。（必需）fromtorch.utils.dataimportDatasetclassCustomImageFolder(Dataset):def__init__(self,targ_dir:str,transform None) >None:self.paths list(pathlib.Path(targ_dir).glob(\"*/*.jpg\"))self.transform transformself.classes,self.class_to_idx find_classes(targ_dir)defload_image(self,index:int) >Image.Image:image_path self.paths[index]returnImage.open(image_path)def__len__(self) >int:returnlen(self.paths)def__getitem__(self,index:int) >Tuple[torch.Tensor,int]:img self.load_image(index)class_name self.paths[index].parent.name#要求data_folder/class_name/image.jpegclass_idx self.class_to_idx[class_name]ifself.transform:returnself.transform(img),class_idx#(X,y)else:returnimg,class_idx#(X,y)重新设置数据转变器：train_transforms transforms.Compose([transforms.Resize((64,64)),transforms.RandomHorizontalFlip(p 0.5),transforms.ToTensor()])test_transforms transforms.Compose([transforms.Resize((64,64)),transforms.ToTensor()])接着实例化数据：train_data_custom CustomImageFolder(targ_dir train_dir,transform train_transforms)test_data_custom CustomImageFolder(targ_dir test_dir,transform test_transforms)train_data_custom.classes,train_data_custom.class_to_idx,len(train_data_custom),len(test_data_custom)###测试`__getitem__`直接上函数：#1.TakeinaDatasetaswellasalistofclassnamesdefdisplay_random_images(dataset:torch.utils.data.dataset.Dataset,classes:List[str] None,n:int 10,display_shape:bool True,seed:int None):#2.Adjustdisplayifntoohighifn>10:n 10display_shape Falseprint(f\"Fordisplaypurposes,nshouldn'tbelargerthan10,settingto10andremovingshapedisplay.\")#3.Setrandomseedifseed:random.seed(seed)#4.Getrandomsampleindexesrandom_samples_idx random.sample(range(len(dataset)),k n)#5.Setupplotplt.figure(figsize (16,5))#6.Loopthroughsamplesanddisplayrandomsamplesfori,targ_sampleinenumerate(random_samples_idx):targ_image,targ_label dataset[targ_sample][0],dataset[targ_sample][1]#7.Adjustimagetensorshapeforplotting:[color_channels,height,width] >[color_channels,height,width]targ_image_adjust targ_image.permute(1,2,0)#Plotadjustedsamplesplt.subplot(1,n,i+1)plt.imshow(targ_image_adjust)plt.axis(\"off\")ifclasses:title f\"class:{classes[targ_label]}\"ifdisplay_shape:title title+f\"\\nshape:{targ_image_adjust.shape}\"plt.title(title)调用测试：#DisplayrandomimagesfromImageFoldercreatedDatasetdisplay_random_images(train_data,n 5,classes class_names,seed None)display_random_images(train_data_custom,n 5,classes class_names,seed None)#Trysettingtheseedforreproducibleimages看起来生效。###把自定义数据类变成DataLoader通过`CustomImageFolder`类，可以将原始图像转换为数据集（特征映射到标签或X映射到y）。因为自定义数据集的继承`torch.utils.data`，所以可以通过`torch.utils.data.DataLoader()`直接使用它们。fromtorch.utils.dataimportDataLoadertrain_dataloader_custom DataLoader(dataset train_data_custom,batch_size 1,num_workers 0,shuffle True)test_dataloader_custom DataLoader(dataset test_data_custom,batch_size 1,num_workers 0,shuffle False)最后获取`train_dataloader_custom`中每个可迭代项的Shape信息：img_custom,label_custom next(iter(train_dataloader_custom))img_custom.shape,label_custom.shape##其他形式的转换（数据增强）目前已经看到了对数据的一些变换，但还有更多，可以在[torchvision.transforms文档](https://pytorch.org/vision/stable/transforms.html)中查阅。变换的目的是以某种方式改变图像，如裁剪、随机删除部分、随即旋转等等。进行这类转换通常被称为数据增强。数据增强是通过人为地增加训练集的多样性来改变数据的过程。对图像执行数据增强的许多示例在：[https://pytorch.org/vision/main/auto_examples/transforms/plot_transforms_illustrations.html](https://pytorch.org/vision/main/auto_examples/transforms/plot_transforms_illustrations.html)研究表明，随机变换（如`transform.RandAugment()`和`transform.TrivialAugmentWide()`）通常比手工选择的变换表现得更好。在`transforms.TrivialAugmentWide()`中需要注意的主要参数是`num_magnitude_bins 31`。 它定义了将选择多少范围的强度值来应用某个转换，0表示没有范围，31表示最大范围（最高强度的最高机会）。将`transforms.TrivialAugmentWide()`合并到`transforms.Compose()`中：fromtorchvisionimporttransformstrain_transforms transforms.Compose([transforms.Resize((224,224)),transforms.TrivialAugmentWide(num_magnitude_bins 31),transforms.ToTensor()])test_transforms transforms.Compose([transforms.Resize((224,224)),transforms.ToTensor()])看看效果：image_path_list list(image_path.glob(\"*/*/*.jpg\"))plot_transformed_images(image_paths image_path_list,transform train_transforms,n 3,seed None)##模型0：没有数据增强的TinyVGG定义transform：simple_transform transforms.Compose([transforms.Resize((64,64)),transforms.ToTensor(),])加载数据：importosfromtorchvisionimportdatasetsfromtorch.utils.dataimportDataLoadertrain_data_simple datasets.ImageFolder(root train_dir,transform simple_transform)test_data_simple datasets.ImageFolder(root test_dir,transform simple_transform)BATCH_SIZE 32NUM_WORKERS 3#个人修改，不全部使用print(f\"batchsize:{BATCH_SIZE},workers:{NUM_WORKERS}\")train_dataloader_simple DataLoader(train_data_simple,batch_size BATCH_SIZE,shuffle True,num_workers NUM_WORKERS)test_dataloader_simple DataLoader(test_data_simple,batch_size BATCH_SIZE,shuffle False,num_workers NUM_WORKERS)len(train_dataloader_simple),len(test_dataloader_simple)batch size: 32, workers: 3直接创建模型，同视觉一节：classTinyVGG(nn.Module):\"\"\"ModelarchitecturecopyingTinyVGGfrom:https://poloclub.github.io/cnn explainer/\"\"\"def__init__(self,input_shape:int,hidden_units:int,output_shape:int) >None:super().__init__()self.conv_block_1 nn.Sequential(nn.Conv2d(input_shape,hidden_units,kernel_size 3,stride 1,padding 1),nn.ReLU(),nn.Conv2d(hidden_units,hidden_units,kernel_size 3,stride 1,padding 1),nn.ReLU(),nn.MaxPool2d(kernel_size 2,stride 2))self.conv_block_2 nn.Sequential(nn.Conv2d(hidden_units,hidden_units,kernel_size 3,padding 1),nn.ReLU(),nn.Conv2d(hidden_units,hidden_units,kernel_size 3,padding 1),nn.ReLU(),nn.MaxPool2d(2))self.classifier nn.Sequential(nn.Flatten(),nn.Linear(in_features hidden_units*16*16,out_features output_shape))defforward(self,x:torch.Tensor):returnself.classifier(self.conv_block_2(self.conv_block_1(x)))torch.manual_seed(42)model_0 TinyVGG(input_shape 3,#(3,RGB)hidden_units 10,output_shape len(train_data.classes)).to(device)model_0###使用`torchinfo`了解模型形状需要安装`torchinfo`库：`pipinstalltorchinfo`。使用：`summary(model,input_size (batch_size,model_shape))`fromtorchinfoimportsummarysummary(model_0,input_size [1,3,64,64])#对示例输入大小进行测试传递`torchinfo.summary()`的输出提供了关于模型的大量信息。 `Totalparams`是模型中参数的总数； `EstimatedTotalSize`是估计的总大小（MB）。还可以看到输入和输出形状的变化，因为特定`input_size`的数据在模型中移动。###封装每step的训练和测试函数deftrain_step(model:torch.nn.Module,dataloader:torch.utils.data.DataLoader,loss_fn:torch.nn.Module,optimizer:torch.optim.Optimizer):model.train()train_loss,train_acc 0,0forbatch,(X,y)inenumerate(dataloader):X,y X.to(device),y.to(device)y_pred model(X)loss loss_fn(y_pred,y)train_loss+ loss.item()optimizer.zero_grad()loss.backward()optimizer.step()y_pred_class torch.argmax(torch.softmax(y_pred,dim 1),dim 1)train_acc+ (y_pred_class y).sum().item()/len(y_pred)train_loss train_loss/len(dataloader)train_acc train_acc/len(dataloader)returntrain_loss,train_accdeftest_step(model:torch.nn.Module,dataloader:torch.utils.data.DataLoader,loss_fn:torch.nn.Module):model.eval()test_loss,test_acc 0,0withtorch.inference_mode():forbatch,(X,y)inenumerate(dataloader):X,y X.to(device),y.to(device)test_pred_logits model(X)loss loss_fn(test_pred_logits,y)test_loss+ loss.item()test_pred_labels test_pred_logits.argmax(dim 1)test_acc+ ((test_pred_labels y).sum().item()/len(test_pred_labels))test_loss test_loss/len(dataloader)test_acc test_acc/len(dataloader)returntest_loss,test_acc###封装训练函数deftrain(model:torch.nn.Module,train_dataloader:torch.utils.data.DataLoader,test_dataloader:torch.utils.data.DataLoader,optimizer:torch.optim.Optimizer,loss_fn:torch.nn.Module nn.CrossEntropyLoss(),epochs:int 5):results {\"train_loss\":[],\"train_acc\":[],\"test_loss\":[],\"test_acc\":[]}forepochinrange(epochs):train_loss,train_acc train_step(model model,dataloader train_dataloader,loss_fn loss_fn,optimizer optimizer)test_loss,test_acc test_step(model model,dataloader test_dataloader,loss_fn loss_fn)print(f\"Epoch:{epoch+1}\"f\"train_loss:{train_loss:.4f}\"f\"train_acc:{train_acc:.4f}\"f\"test_loss:{test_loss:.4f}\"f\"test_acc:{test_acc:.4f}\")results[\"train_loss\"].append(train_loss.item()ifisinstance(train_loss,torch.Tensor)elsetrain_loss)results[\"train_acc\"].append(train_acc.item()ifisinstance(train_acc,torch.Tensor)elsetrain_acc)results[\"test_loss\"].append(test_loss.item()ifisinstance(test_loss,torch.Tensor)elsetest_loss)results[\"test_acc\"].append(test_acc.item()ifisinstance(test_acc,torch.Tensor)elsetest_acc)returnresults###构建训练和测试循环torch.manual_seed(42)torch.cuda.manual_seed(42)NUM_EPOCHS 5model_0 TinyVGG(input_shape 3,#3,RGBhidden_units 10,output_shape len(train_data.classes)).to(device)loss_fn nn.CrossEntropyLoss()optimizer torch.optim.Adam(params model_0.parameters(),lr 0.001)fromtimeitimportdefault_timerastimerstart_time timer()model_0_results train(model model_0,train_dataloader train_dataloader_simple,test_dataloader test_dataloader_simple,optimizer optimizer,loss_fn loss_fn,epochs NUM_EPOCHS)end_time timer()print(f\"耗时:{end_time start_time:.3f}seconds\")Epoch: 1 train_loss: 1.1078 train_acc: 0.2578 test_loss: 1.1362 test_acc: 0.2604 Epoch: 2 train_loss: 1.0846 train_acc: 0.4258 test_loss: 1.1622 test_acc: 0.1979 Epoch: 3 train_loss: 1.1153 train_acc: 0.2930 test_loss: 1.1695 test_acc: 0.1979 Epoch: 4 train_loss: 1.0990 train_acc: 0.2891 test_loss: 1.1343 test_acc: 0.1979 Epoch: 5 train_loss: 1.0989 train_acc: 0.2930 test_loss: 1.1435 test_acc: 0.1979 耗时: 46.904 seconds效果很差，试试可视化损失，封装函数：defplot_loss_curves(results:Dict[str,List[float]]):\"\"\"Plotstrainingcurvesofaresultsdictionary.Args:results(dict):dictionarycontaininglistofvalues,e.g.{\"train_loss\":[...],\"train_acc\":[...],\"test_loss\":[...],\"test_acc\":[...]}\"\"\"#Getthelossvaluesoftheresultsdictionary(trainingandtest)loss results['train_loss']test_loss results['test_loss']#Gettheaccuracyvaluesoftheresultsdictionary(trainingandtest)accuracy results['train_acc']test_accuracy results['test_acc']#Figureouthowmanyepochstherewereepochs range(len(results['train_loss']))#Setupaplotplt.figure(figsize (10,3))#Plotlossplt.subplot(1,2,1)plt.plot(epochs,loss,label 'train_loss')plt.plot(epochs,test_loss,label 'test_loss')plt.title('Loss')plt.xlabel('Epochs')plt.legend()#Plotaccuracyplt.subplot(1,2,2)plt.plot(epochs,accuracy,label 'train_accuracy')plt.plot(epochs,test_accuracy,label 'test_accuracy')plt.title('Accuracy')plt.xlabel('Epochs')plt.legend();调用：plot_loss_curves(model_0_results)##探究损失函数查看训练和测试损失曲线是查看模型是否过拟合的好方法。 过拟合模型是在训练集上比在验证/测试集上表现更好，训练损失远低于测试损失。 当训练和测试损失没有想要的那么低时，这被认为是欠拟合。训练和测试损失曲线的理想位置是它们彼此紧密排列。###处理过拟合由于过拟合的主要问题是模型太好地拟合训练数据，防止过拟合的一种常见技术称为正则化。预防过拟合的操作： 使用更多数据：拥有更多的数据使模型有更多的机会学习样式，这些样式可能更容易推广到新的示例。 简化模型：如果当前模型已经过拟合训练数据，则模型可能过于复杂。这意味着它对数据的模式学习得太好，无法很好地推广到看不见的数据。简化模型的一种方法是减少它使用的层数或减少每层中隐藏单元的数量。 数据增强：人为地为数据添加了更多的多样性。如果模型能够学习增强数据中的模式，则模型可能能够更好地概括看不见的数据。 迁移学习：迁移学习涉及利用一个模型已经学会使用的模式（也称为预训练权重）作为您自己任务的基础。在此例子中，可以使用一个在各种图像上预训练的计算机视觉模型，然后稍微调整它，使其更专门用于食物图像。 使用dropout层：dropout层随机删除神经网络中隐藏层之间的连接，有效地简化了模型，也使剩余的连接更好。 使用衰减的学习率：在模型训练时慢慢降低学习率。越接近收敛，越希望权重更新越小。 使用早停：早期停止在模型训练开始过度拟合之前停止。例如，假设模型的损失在过去10（这个数字是任意的）个epoch中停止下降，可能希望在这里停止模型训练，并使用损失最低的模型权重（10epoch之前）。###处理欠拟合当模型拟合不足时，它被认为对训练集和测试集的预测能力较差。从本质上讲，欠拟合模型将无法将损失值降低到期望的水平。目前的损失曲线，认为TinyVGG模型model_0对数据拟合不足。处理欠拟合背后的主要思想是提高模型的预测能力。处理欠拟合的操作： 增加模型隐藏层或隐层神经元：如果模型拟合不足，可能没有足够的能力来学习所需的模式/权重/数据表示来进行预测。为模型添加更多预测能力的一种方法是增加这些层中隐藏层/单元的数量。 调整学习率：也许模型的学习率太高了。而且它试图在每个时期更新权重太多，从而无法学习任何东西。在这种情况下，可以降低学习率。 使用迁移学习：迁移学习能够防止过拟合和欠拟合。它涉及到使用以前工作模型中的模式，并根据当前问题进行调整。 训练更长时间：模型可能需要更多的时间来学习数据的表示。如果你在小型实验中发模型没有学习到任何东西，也许让它训练更多的epoch可能会带来更好的性能。 减少正则化：也许因为试图防止过度拟合导致模型是欠拟合的。##模型1：数据增强后的TinyVGG修改数据transform：train_transform_trivial_augment transforms.Compose([transforms.Resize((64,64)),transforms.TrivialAugmentWide(num_magnitude_bins 31),transforms.ToTensor()])test_transform transforms.Compose([transforms.Resize((64,64)),transforms.ToTensor()])再次处理数据集：train_data_augmented datasets.ImageFolder(train_dir,transform train_transform_trivial_augment)test_data_simple datasets.ImageFolder(test_dir,transform test_transform)train_data_augmented,test_data_simple转成DataLoader：BATCH_SIZE 32NUM_WORKERS 3torch.manual_seed(42)train_dataloader_augmented DataLoader(train_data_augmented,batch_size BATCH_SIZE,shuffle True,num_workers NUM_WORKERS)test_dataloader_simple DataLoader(test_data_simple,batch_size BATCH_SIZE,shuffle False,num_workers NUM_WORKERS)重新实例化模型：torch.manual_seed(42)model_1 TinyVGG(input_shape 3,hidden_units 10,output_shape len(train_data_augmented.classes)).to(device)model_1开始训练：torch.manual_seed(42)torch.cuda.manual_seed(42)NUM_EPOCHS 5loss_fn nn.CrossEntropyLoss()optimizer torch.optim.Adam(params model_1.parameters(),lr 0.001)start_time timer()model_1_results train(model model_1,train_dataloader train_dataloader_augmented,test_dataloader test_dataloader_simple,optimizer optimizer,loss_fn loss_fn,epochs NUM_EPOCHS)end_time timer()print(f\"耗时:{end_time start_time:.3f}seconds\")Epoch: 1 train_loss: 1.1073 train_acc: 0.2500 test_loss: 1.1060 test_acc: 0.2604 Epoch: 2 train_loss: 1.0793 train_acc: 0.4258 test_loss: 1.1380 test_acc: 0.2604 Epoch: 3 train_loss: 1.0805 train_acc: 0.4258 test_loss: 1.1684 test_acc: 0.2604 Epoch: 4 train_loss: 1.1287 train_acc: 0.3047 test_loss: 1.1618 test_acc: 0.2604 Epoch: 5 train_loss: 1.0895 train_acc: 0.4258 test_loss: 1.1470 test_acc: 0.2604 耗时: 47.582 seconds看起来效果也不好，绘制损失趋势图：plot_loss_curves(model_1_results)##比较并评估模型使用`pandas`并绘图：importpandasaspdmodel_0_df pd.DataFrame(model_0_results)model_1_df pd.DataFrame(model_1_results)#Setupaplotplt.figure(figsize (15,8))#Getnumberofepochsepochs range(len(model_0_df))#Plottrainlossplt.subplot(2,2,1)plt.plot(epochs,model_0_df[\"train_loss\"],label \"Model0\")plt.plot(epochs,model_1_df[\"train_loss\"],label \"Model1\")plt.title(\"TrainLoss\")plt.xlabel(\"Epochs\")plt.legend()#Plottestlossplt.subplot(2,2,2)plt.plot(epochs,model_0_df[\"test_loss\"],label \"Model0\")plt.plot(epochs,model_1_df[\"test_loss\"],label \"Model1\")plt.title(\"TestLoss\")plt.xlabel(\"Epochs\")plt.legend()#Plottrainaccuracyplt.subplot(2,2,3)plt.plot(epochs,model_0_df[\"train_acc\"],label \"Model0\")plt.plot(epochs,model_1_df[\"train_acc\"],label \"Model1\")plt.title(\"TrainAccuracy\")plt.xlabel(\"Epochs\")plt.legend()#Plottestaccuracyplt.subplot(2,2,4)plt.plot(epochs,model_0_df[\"test_acc\"],label \"Model0\")plt.plot(epochs,model_1_df[\"test_acc\"],label \"Model1\")plt.title(\"TestAccuracy\")plt.xlabel(\"Epochs\")plt.legend();最后封装一个函数，使得可以外部输入图片路径，然后进行预测：importtorchvisiondefpred_and_plot_image(model:torch.nn.Module,image_path:str,class_names:List[str] None,transform None,device:torch.device device):\"\"\"Makesapredictiononatargetimageandplotstheimagewithitsprediction.\"\"\"#1.加载图像并将张量值转换为float32target_image torchvision.io.read_image(str(image_path)).type(torch.float32)#2.将图像像素值除以255，得到[0,1]之间的值target_image target_image/255.#3.作数据转换iftransform:target_image transform(target_image)#4.确保模型在目标设备上model.to(device)#5.打开模型评估模式model.eval()withtorch.inference_mode():#为图像添加额外的维度target_image target_image.unsqueeze(dim 0)#对具有额外维度的图像进行预测，并将其发送到目标设备target_image_pred model(target_image.to(device))#6.转换logits >预测概率target_image_pred_probs torch.softmax(target_image_pred,dim 1)#7.转换预测概率 >预测标签target_image_pred_label torch.argmax(target_image_pred_probs,dim 1)#8.将图像与预测和预测概率一起绘制plt.imshow(target_image.squeeze().permute(1,2,0))#确保它的大小适合matplotlibifclass_names:title f\"Pred:{class_names[target_image_pred_label.cpu()]}Prob:{target_image_pred_probs.max().cpu():.3f}\"else:title f\"Pred:{target_image_pred_label}Prob:{target_image_pred_probs.max().cpu():.3f}\"plt.title(title)plt.axis(False);test_img_path \"data/pizza_steak_sushi/test/pizza/1687143.jpg\"custom_image_transform transforms.Compose([transforms.Resize((64,64))])pred_and_plot_image(model model_1,image_path test_img_path,class_names class_names,transform custom_image_transform,device device)"},"/StyleTransfer/ref_and_notes/pytorch_install.html":{"title":"PyTorch 安装","content":" title: PyTorch 安装 keywords: PyTorch desc: PyTorch 安装 date: 2025 02 07 id: pytorch Reference: [Zero to Mastery Learn PyTorch for Deep Learning](https://www.learnpytorch.io/) ## PyTorch 基本环境搭建 1. 创建并激活环境 ```bat python m venv [venv name] [venv name]\\Scripts\\activate ``` 2. 安装 Pytorch ```bat pip install torch torchvision torchaudio ``` 验证 Pytorch 安装，出现版本号则为正常。 ## PyTorch GPU 环境搭建 在搭建虚拟环境后，如果需要在 GPU 上运行，需要安装 PyTorch GPU 版本。 1. 确定自己的 GPU CUDA 版本。 ```bat nvidia smi ``` 2. 下载对应的 PyTorch GPU 版本。[官方引导下载](https://pytorch.org/get started/locally/) 附镜像页面链接： PyTorch官方镜像 [Torch](https://download.pytorch.org/whl/torch/) [TorchVision](https://download.pytorch.org/whl/torchvision/) [TorchAudio](https://download.pytorch.org/whl/torchaudio/) [阿里云镜像源](https://mirrors.aliyun.com/pytorch wheels/) 支持的 CUDA：10.0、10.1、10.2、11.0、11.1、11.3、11.5、11.6、11.7、11.8、12.1 3. 检测是否可用。 ```python import torch print(torch.cuda.is_available()) ```"},"/StyleTransfer/ref_and_notes/pytorch_tensor.html":{"title":"PyTorch 张量","content":"Reference:[ZerotoMasteryLearnPyTorchforDeepLearning](https://www.learnpytorch.io/)*该页面由JupyterNotebook生成，原文件于[Github](https://github.com/Fingsinz/StyleTransfer/tree/main/src/02.pytorch_learning/pytorch_tensor.ipynb)*importtorchtorch.__version__##什么是张量张量用于表示数据，是机器学习的基本组成部分。 图片可以是三维张量，如`[height,width,channel]`，如经典的lena图片用张量表示：importnumpyasnpfromPILimportImage#使用pillow打开图片,转换为numpy矩阵,再转换为torch张量img torch.from_numpy(np.array(Image.open(\"imgs/lena.jpg\")))img.shape##创建张量Tensors说明文档：[https://pytorch.org/docs/stable/tensors.html](https://pytorch.org/docs/stable/tensors.html)1.Scalar，标量是一个单独的数字，用张量的术语来说是一个零维张量。scalar torch.tensor(3.0)#维度同样可以通过tensor.dim()获取print(f\"scalar为{scalar},维度为{scalar.ndim},常量通过item方法获取{scalar.item()}数字\")scalar为3.0, 维度为0, 常量通过item方法获取3.0数字2.Vector，向量是一个一维张量，类似于数组。vector torch.tensor([1.0,2.0,3.0])print(f\"vector为{vector},维度为{vector.ndim},通过shape属性获取形状{vector.shape}\")vector为tensor([1., 2., 3.]), 维度为1, 通过shape属性获取形状torch.Size([3])3.Matrix，矩阵是一个二维张量。matrix torch.tensor([[1.0,2.0,3.0],[4.0,5.0,6.0]])print(f\"{matrix},\\n维度为{matrix.ndim},通过shape属性获取形状{matrix.shape}\")tensor([[1., 2., 3.], [4., 5., 6.]]), 维度为2, 通过shape属性获取形状torch.Size([2, 3])总结：结构表示维度: :: :: :scalar一个数字0vector一组数字1matrix一个矩阵2tensor若干维度0维表示scalar，每一维表示一个vector###`torch.rand()`生成随机张量实际上在机器学习中很少会手动创建张量，更多是随机生成。#创建指定大小的随机张量random_tensor torch.rand(size (3,4))random_tensor,random_tensor.dtype###填充全零或全一张量zeros torch.zeros(size (3,4))ones torch.ones(size (3,4))zeros,zeros.dtypeones,ones.dtype###创建一个范围张量#创建一个从0到9的张量的两种方法#zero_to_ten1 torch.range(0,10)#将弃用zero_to_ten2 torch.arange(start 0,end 10,step 1)#zero_to_ten1,zero_to_ten1.dtypezero_to_ten2,zero_to_ten2.dtype#创建一个形状一样的向量same_shape torch.zeros_like(input zero_to_ten2)same_shape,same_shape.dtype##张量数据类型Tensor的DataTypes：[https://pytorch.org/docs/stable/tensors.html#data types](https://pytorch.org/docs/stable/tensors.html#data types)有些数据类型是特定于CPU，而有些更适合GPU。同时确保精度问题，可以选用不同精度的浮点数类型。float32_tensor torch.tensor([3.0,6.0,9.0],dtype None,#默认为None，即torch。Float32或传递的任何数据类型device None,#默认为None，使用默认的张量类型requires_grad False)#如果为True，则记录对张量执行的操作float32_tensor.shape,float32_tensor.dtype,float32_tensor.device可以修改张量的数据类型：float64_tensor float32_tensor.type(torch.float64)float64_tensor.dtype在进行带张量的操作时，除了张量的Shape要匹配之外，还需要注意张量的dtype和device。 `tensor.shape`：获取Shape。 `tensor.dtype`：获取dtype。 `tensor.device`：获取device。##张量的操作###张量的基础操作张量的加减乘操作如下：test_tensor torch.tensor([1,2,3])test_tensor+10,test_tensor*10,test_tensor 1,test_tensor#在不赋值的时候是不变的也可以通过函数实现：torch.add(test_tensor,10),torch.mul(test_tensor,10),torch.sub(test_tensor,1)注意，**矩阵乘法遵循其规则，与形状相关。**$$M_{m\\timesn} M_{m\\timesk}@M_{k\\timesn}$$*`@`在Python中是矩阵乘法*tensor torch.tensor([1,2,3])tensor*tensor,tensor@tensor,torch.matmul(tensor,tensor)#torch.matmul是矩阵乘法，且比@操作更快 $[1,2,3]*[1,2,3] [1*1,2*2,3*3] [1,4,9]$ $[1,2,3]@[1,2,3] 1*1+2*2+3*3 14$`torch.mm()`是`torch.matmul()`的缩写。另外提供一些操作进行矩阵变换： `torch.transpose(input,dim0,dim1)`，`input`是输入矩阵，`dim0`和`dim1`是要交换的维度。 `torch.T`：转置矩阵。###求最小值、最大值、平均值、总和等x torch.arange(0,100,10)print(x)print(f\"最小值:{x.min()}\")print(f\"最大值:{x.max()}\")#print(f\"Mean:{x.mean()}\")#会报错print(f\"均值:{x.type(torch.float32).mean()}\")#没有float数据类型将无法工作print(f\"总和:{x.sum()}\")tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90]) 最小值: 0 最大值: 90 均值: 45.0 总和: 450*一些方法，如torch.mean()，要求张量位于torch.float32（最常见）或其他特定数据类型中，否则操作将失败。*###求最小最大值的位置print(x)print(f\"Indexwheremaxvalueoccurs:{x.argmax()}\")print(f\"Indexwhereminvalueoccurs:{x.argmin()}\")tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90]) Index where max value occurs: 9 Index where min value occurs: 0###张量形状重塑、堆叠、挤压和扩展因为深度学习模型（神经网络）都是关于以某种方式操纵张量的。因为矩阵乘法的规则，如果有形状不匹配，就会遇到错误。这些方法帮助你确保你的张量的正确元素与其他张量的正确元素混合在一起。方法描述: :: :[torch.reshape(input,shape)](https://pytorch.org/docs/stable/generated/torch.reshape.html#torch.reshape)或`torch.Tensor.reshape()`在兼容的情况下把`input`重塑成`shape`的形状[Tensor.view(shape)](https://pytorch.org/docs/stable/generated/torch.Tensor.view.html)以不同的形状返回原始张量的视图，但与原始张量共享相同的数据[torch.stack(tensors,dim 0)](https://pytorch.org/docs/1.9.1/generated/torch.stack.html)沿着一个新的维度`dim`连接一系列张量，所有张量必须是相同的大小[torch.squeeze(input)](https://pytorch.org/docs/stable/generated/torch.squeeze.html)挤压`input`，删除值为1的所有维度[torch.unsqueeze(input,dim)](https://pytorch.org/docs/1.9.1/generated/torch.unsqueeze.html)在`dim`处添加值为1的维度并返回[torch.permute(input,dims)](https://pytorch.org/docs/stable/generated/torch.permute.html)返回原始输入的视图，其维度重新排列`tensor.reshape()`：importtorchx torch.arange(1.,9.)x_reshaped x.reshape(1,8)#重塑print(f\"x.shape:{x.shape},x_reshaped.shape:{x_reshaped.shape}\")x.shape: torch.Size([8]), x_reshaped.shape: torch.Size([1, 8])`tensor.view()`：改变视图也会改变原来的张量。x_viewed x.view(2,4)#重塑print(f\"x.shape:{x.shape},x_viewed.shape:{x_viewed.shape}\")#修改x_viewd,x同步变化x_viewed[:,0] 5print(x)print(x_viewed)x.shape: torch.Size([8]), x_viewed.shape: torch.Size([2, 4]) tensor([5., 2., 3., 4., 5., 6., 7., 8.]) tensor([[5., 2., 3., 4.], [5., 6., 7., 8.]])用该函数改变一个张量的视图实际上只会创建同一个张量的新视图。如果想要将新张量在自身之上堆叠五次，可以使用`torch.stack()`来实现。x_stacked torch.stack([x,x,x,x],dim 0)x_stacked同时可以移除单维度：print(x_reshaped.shape)x_squzzed x_reshaped.squeeze()print(x_squzzed.shape)torch.Size([1, 8]) torch.Size([8])与`torch.squeeze()`相反，可以使用`torch.unsqueeze()`在特定索引处添加一个维度值1：print(x_squzzed.shape)x_unsquzzed x_squzzed.unsqueeze(dim 0)print(x_unsquzzed.shape)torch.Size([8]) torch.Size([1, 8])`torch.permute(input,dims)`重排张量的维度：img torch.rand(size (128,256,3))img_permuted img.permute(2,0,1)img.shape,img_permuted.shape###张量取下标importtorchx torch.arange(1,10).reshape(1,3,3)print(f\"{x},{x.shape}\")print(f\"x[0]:\\n{x[0]}\")print(f\"x[0][0]:{x[0][0]}\")print(f\"x[0][0][0]:{x[0][0][0]}\")tensor([[[1, 2, 3], [4, 5, 6], [7, 8, 9]]]), torch.Size([1, 3, 3]) x[0]: tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) x[0][0]: tensor([1, 2, 3]) x[0][0][0]: 1*可以使用`:`来指定此维度中的所有值，使用逗号`,`来添加另一个维度。*##Pytorch张量和NumpyNumPy和PyTorch数据结构互转： NumpyArray >PyTorchTensor：`torch.from_numpy(ndarray)`。 PyTorchTensor >NumpyArray：`torch.Tensor.numpy()`。##Tensor随机值`torch.rand()`方法可以生成一个给定大小而值随机的张量，但是每次生成都会不一样。如果需要每次随机都一样，需要固定下随机数种子。importtorchimportrandomRANDOM_SEED 42torch.manual_seed(seed RANDOM_SEED)random_tensor_A torch.rand(3,4)torch.random.manual_seed(seed RANDOM_SEED)random_tensor_B torch.rand(3,4)print(f\"TensorA:\\n{random_tensor_A}\\n\")print(f\"TensorB:\\n{random_tensor_B}\\n\")print(f\"A B?\")print(random_tensor_A random_tensor_B)Tensor A: tensor([[0.8823, 0.9150, 0.3829, 0.9593], [0.3904, 0.6009, 0.2566, 0.7936], [0.9408, 0.1332, 0.9346, 0.5936]]) Tensor B: tensor([[0.8823, 0.9150, 0.3829, 0.9593], [0.3904, 0.6009, 0.2566, 0.7936], [0.9408, 0.1332, 0.9346, 0.5936]]) A B? tensor([[True, True, True, True], [True, True, True, True], [True, True, True, True]])##GPU下使用张量导入PyTorch：importtorchtorch.cuda.is_available()设置设备类型：#Setdevicetypedevice \"cuda\"iftorch.cuda.is_available()else\"cpu\"device检查设备数：torch.cuda.device_count()###张量在CPU和GPU间移动通过调用`to(device)`将张量（和模型）放在特定的设备上。GPU可以提供比CPU更快的数值计算，但有时候某些操作不支持在GPU中执行，所以需要将张量进行移动。张量移动到GPU侧：tensor torch.tensor([1,2,3])print(tensor,tensor.device)tensor_on_gpu tensor.to(device)print(tensor_on_gpu)tensor([1, 2, 3]) cpu tensor([1, 2, 3], device 'cuda:0')张量移动到CPU侧：通过使用`tensor.CPU()`tensor_back_on_cpu tensor_on_gpu.cpu()print(tensor_back_on_cpu)#上面的代码返回CPU内存中GPU张量的副本，原始张量仍然在GPU上。print(tensor_on_gpu)tensor([1, 2, 3]) tensor([1, 2, 3], device 'cuda:0')"},"/StyleTransfer/ref_and_notes/index.html":{"title":"参考文献及笔记","content":" title: 参考文献及笔记 keywords: desc: 参考文献阅读及其代码测试 date: 2025 01 16 1. 原始GAN: [Generative Adversarial Networks](https://arxiv.org/abs/1406.2661)"}}